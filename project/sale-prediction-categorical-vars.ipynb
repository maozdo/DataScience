{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2021-09-25T14:25:59.296163Z","iopub.execute_input":"2021-09-25T14:25:59.298297Z","iopub.status.idle":"2021-09-25T14:26:00.658272Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n############################################################################\n#####   Package mechkar                                                 ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2017-05-01                                       ####\n############################################################################\n\n############################################################################\n#####   DATA VISUALIZATION                                              ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2014-03-12                                       ####\n#####   Last Modified: 2020-11-03                                       ####\n############################################################################\n\n###########  Functions   ##############################################\n\n###################################################\n\nexploreData <- function(data=data, y=NULL, rn=NULL, factorSize=10, dir=tempdir(), debug=FALSE, ...) {\n\n  whatVarType <- function(var) {\n    suppressWarnings(if (var==\"integer\" | var==\"numeric\") {\n      return(1)\n    } else if (var==\"factor\" | var==\"character\") {\n      return(2)\n    } else if (var==\"Date\" | \"POSIXct\" %in% var[[1]]) {\n      return(3)\n    } else {\n      return(0)\n    })\n  }\n\n  drawHistogram <- function(imgname=imgname, x=x) {\n    d=stats::density(x, kernel = \"gaussian\",na.rm=TRUE)\n    breakstar=(max(x,na.rm=TRUE) -min(x,na.rm=TRUE))/d$bw\n    h=graphics::hist(x, breaks=breakstar)\n    graphics::plot(h,main=\"\",xlab=imgname)\n    yfit<-seq(min(x,na.rm=TRUE),max(x,na.rm=TRUE),length=40)\n    ffit<-stats::dnorm(yfit,mean=mean(x,na.rm=TRUE),sd=stats::sd(x,na.rm=TRUE))\n    ffit <- ffit*diff(h$mids[1:2])*length(x)\n    lines(yfit, ffit, col=\"blue\", lwd=2)\n  }\n\n  drawFakeGraph <- function(imgname=imgname) {\n    graphics::plot.window(xlim = c(0,0),ylim = c(0,0))\n  }\n\n  drawBars <- function(imgname=imgname, x=x) {\n    graphics::plot(x)\n  }\n\n  drawGraphOne <- function(imgname=imgname, numVar=x, vartype=1) {\n    if(vartype==1) {\n      drawHistogram(imgname,numVar)\n    } else if(vartype==2) {\n      drawBars(imgname,numVar)\n    } else {\n      drawFakeGraph(imgname)\n    }\n  }\n\n  getContinuousStats <- function(x) {\n    N <- length(x)\n    n <- length(x[which(is.na(x)==FALSE)])\n    pct <- formatC(n/N * 100)\n    nmiss <- length(x[which(is.na(x)==TRUE)])\n    npct <- formatC(nmiss/N *100)\n    ma <- mean(x, na.rm=TRUE)\n    s <- stats::sd(x, na.rm=TRUE)\n    me <- formatC(stats::median(x, na.rm=TRUE))\n    q1 <- formatC(stats::quantile(x,1/4, na.rm=TRUE))\n    q3 <- formatC(stats::quantile(x,3/4, na.rm=TRUE))\n    mn <- formatC(min(x, na.rm=TRUE))\n    mx <- formatC(max(x, na.rm=TRUE))\n    html <- paste(\"<div class='Cell' style='align: top;'> <u>Data type</u>: Continuous <p> <u>Data length</u>: \",n ,\"/\", N, \" (\", pct, \"%) <br> <u>Missing</u>: \",\n                  nmiss, \" (\", npct, \"%)<p> <u>Mean</u>: \", formatC(ma), \"\\t <u>StdDev</u>: \", formatC(s), \"<br><u>Median</u>: \",me,\n                  \"\\t <u>IQR</u>: \", q1, \"-\", q3, \"<br><u>Min</u>: \", mn, \"\\t <u>Max</u>: \", mx, \"</div>\")\n    return(html)\n  }\n\n  getCategortyStats <- function(x) {\n    N <- length(x)\n    n <- length(x[which(is.na(x)==FALSE)])\n    pct <- formatC(n/N * 100)\n    nmiss <- length(x[which(is.na(x)==TRUE)])\n    npct <- formatC(nmiss/N *100)\n    l <- levels(x)\n    s <- summary(x)\n    htm <- \"<ul>\"\n    if (length(l) < 5) {\n      for (lv in l) {\n        htm <- paste(htm, \"<li><u>\", lv, \"</u>: \", s[[lv]], \"</li>\")\n      }\n      htm <- paste(htm,\"</ul>\")\n    }\n    html <- paste(\"<div class='Cell'> <u>Data type</u>: Categorical Data <p> <u>Data length</u>: \",n, \"/\", N, \" (\", pct, \"%) <br> <u>Missing</u>: \",\n                  nmiss, \" (\", npct, \"%) <p> <u>Number of levels</u>: \", length(l), \"<br>\", htm, \"</div>\")\n    return(html)\n  }\n\n  getDatesStats <- function(x) {\n    N <- length(x)\n    n <- length(x[which(is.na(x)==FALSE)])\n    pct <- formatC(n/N * 100)\n    nmiss <- length(x[which(is.na(x)==TRUE)])\n    npct <- formatC(nmiss/N *100)\n    s <- summary(x)\n    html <- paste(\"<div class='Cell'> <u>Data type</u>: Date <p> <u>Data length</u>: \",n, \"/\", N, \" (\", pct, \"%) <br> <u>Missing</u>: \",\n                  nmiss, \" (\", npct, \"%) <p> <u>Min date</u>: \", min(x, na.rm=TRUE), \"<br><u>Max date</u>:\",max(x, na.rm=TRUE) , \"</div>\")\n    return(html)\n  }\n\n  getStats <- function(numVar=x, vartype=1) {\n    if(vartype==1) {\n      html <- getContinuousStats(numVar)\n    } else if(vartype==2) {\n      html <- getCategortyStats(numVar)\n    } else if (vartype==3) {\n      html <- getDatesStats(numVar)\n    } else {\n      html <- \"<div class='Cell'></div>\"\n    }\n    return(html)\n  }\n\n  getOutliers <- function(x) {\n    bp <- graphics::boxplot(x,plot=FALSE)\n    return(bp$out)\n  }\n\n  getOutlierGraph <- function(x) {\n    #  mod <- tryCatch({\n    outl <- getOutliers(x)\n    df <- data.frame(x=x, cl=1)\n    if(length(outl)>0) {\n      df$cl[which(df$x %in% outl)] <- 2\n    }\n    #pl <- stats::scatter.smooth(df$x,col=df$cl)\n    pl <- tryCatch({\n      stats::scatter.smooth(df$x,col=df$cl,xlab=\"index\")\n    }, warning = function(w) {\n      suppressWarnings(w)\n      #n <- \"warning!\"\n    }, error = function(e) {\n      n <- \"error!\"\n    }, finally = {\n      graphics::plot(df$x ~ row.names(df),col=df$cl,xlab=\"index\")\n    })\n    ma <- mean(x, na.rm=TRUE)\n    s <- stats::sd(x, na.rm=TRUE)\n    graphics::abline(h=ma-(2*s), col=\"red\", lty=2)\n    graphics::abline(h=ma+(2*s), col=\"red\", lty=2)\n    #  }, error = function(e) {\n    #    pl <- drawFakeGraph(\"none\")\n    #  })\n    return(pl)\n  }\n\n  #' @importFrom rlang .data\n  getScatterGraph <- function(df=data,x,y,dtype=1) {\n    if(dtype==1) {\n      pl <- ggplot2::ggplot(df) + ggplot2::geom_smooth(ggplot2::aes(x=.data[[x]], y=.data[[y]]), method=\"loess\") + ggplot2::xlab(x) + ggplot2::ylab(y)\n    } else {\n      pl <- ggplot2::ggplot(df) + ggplot2::geom_boxplot(ggplot2::aes(y=.data[[x]], color=.data[[y]])) + ggplot2::xlab(x) + ggplot2::ylab(y) + ggplot2::labs(color=y)\n    }\n    return(pl)\n  }\n\n  getOutliersHtml <- function(imgname=imgname, x=x, srcdir=srcdir) {\n    bp <- getOutliers(x)\n    if (length(unique(bp)) > 10) {\n      xtrm <- paste(\"There are \", length(unique(bp)), \" outlier values\")\n    } else if (length(unique(bp)) == 0) {\n      xtrm <- \"No outlier values found\"\n    } else {\n      xtrm <- paste(formatC(unique(bp)), collapse=', ' )\n    }\n    #imgsrc = paste(paste0(srcdir,\"/fig/\"),imgname, \"_2.png\",sep=\"\")\n    imgsrc = paste(paste0(\"fig/\"),imgname, \"_2.png\",sep=\"\")\n    html <- paste0(\"<div class='Cell'><img class='origimg' src='\",imgsrc,\"' height='150' width='250'><br> <u>Outlier values</u>: <br> \", xtrm, \"</div>\")\n    return(html)\n  }\n  ################## Prepare for the report ###################\n  #report <- paste(mydir,\"/report\",sep=\"\")\n\n  ################## Check for values for rn ##################\n  if(!is.null(rn)) {\n    if(length(rn)!=ncol(data)) {\n      message(\"the value of the 'rn' argument was avoided because it does not have the same number of columns of the dataframe\")\n      rn <- NULL\n    }\n    xname <- rn\n    names(xname) <- names(data)\n  } else {\n    xname <- NULL\n  }\n\n  report <- dir\n  if (!file.exists(report)) {\n    dir.create(report)\n  }\n  fig <- paste(report,\"/fig\",sep=\"\")\n  if (!file.exists(fig)) {\n    dir.create(fig)\n  }\n  srcdir <- report\n\n  # determine which columns are integer\n  int_col <- which(sapply(data, is.integer))\n  int_col <- c(int_col,(which(sapply(data, is.numeric))))\n  mi <- vector()\n  # find only those integers with less than 10 unique values and convert to factor\n  for (li in int_col) {\n    if (length(unique(data[,li])) < factorSize) {\n      mi <- c(mi,li)\n      if (is.factor(data[,li]) == FALSE) {\n        data[,li] <- factor(data[,li])\n      }\n    }\n  }\n\n  str_col <- which(sapply(data, is.character))\n  mi <- vector()\n  # find only those integers with less than 10 unique values and convert to factor\n  for (li in str_col) {\n    mi <- c(mi,li)\n    data[,li] <- factor(data[,li])\n  }\n\n  # create the html report page\n  myhtml <- paste(report,\"/report.html\",sep=\"\")\n  cat(\"<!DOCTYPE html>\n      <html>\n      <head>\n      <title>Data Visualization</title>\n      <meta http-equiv='Content-Type' content='text/html; charset=UTF-8' />\n      <link rel='stylesheet' href='http://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.css'>\n      <script src='http://code.jquery.com/jquery-1.10.2.js'></script>\n      <script>\n      $(document).ready(function(){\n      $('.onetoone').hide();\n      });\n      $(function() {\n      $('.origimg').click(function(e) {\n      $('#popup_img').attr('src',$(this).attr('src'));\n      $('#myContainer').hide();\n      var pos = $(document).scrollTop();\n      $('#myContainer').css({'top':pos+20,'left':250, 'position':'absolute', 'border':'1px solid black', 'padding':'0px'});\n      $('#myContainer').show();\n      });\n      $('#myContainer').click(function(e) {\n      $('#myContainer').hide();\n      });\n      $('#myform2').submit(function(e) {\n      e.preventDefault();\n      });\n      $('#onetoone').on('click',function() {\n      console.log('onetone button - 1');\n      $('#onetoone').hide();\n      $('#aslist').show();\n      // To show only individual rows:\n      $('.Row').hide();\n      $('.onetoone').show();\n      // then we iterate\n      var i = $('.Row').length;\n      // Then we iterate\n      var nxt = $('#idx').val();\n      if (nxt < i & nxt >0) {\n      $('.Row').hide();\n      $('.Row').eq(0).show();\n      $('.Row').eq(nxt).show();\n      } else {\n      $('#idx').val(1)\n      }\n      console.log('onetone button - 2');\n      });\n      $('#aslist').on('click',function() {\n      console.log('aslist button - 1');\n      $('#onetoone').show();\n      $('#aslist').hide();\n      $('.onetoone').hide();\n      $('.Row').show();\n      console.log('aslist button - 2');\n      });\n      $('#less').on('click',function(){\n      console.log('less button - 1');\n      var i = $('.Row').length;\n      var nxt = parseInt($('#idx').val(),10) - 1;\n      if (nxt < i & nxt >0) {\n      $('#idx').val(nxt)\n      $('.Row').hide();\n      $('.Row').eq(0).show();\n      $('.Row').eq(nxt).show();\n      } else {\n      $('#idx').val(1)\n      }\n      console.log('less button - 2');\n      });\n      $('#more').on('click',function(){\n      console.log('more button - 1');\n      var i = $('.Row').length;\n      var nxt = parseInt($('#idx').val(),10) + 1;\n      if (nxt < i & nxt >0) {\n      $('#idx').val(nxt)\n      $('.Row').hide();\n      $('.Row').eq(0).show();\n      $('.Row').eq(nxt).show();\n      } else {\n      $('#idx').val(i)\n      }\n      console.log('more button - 2');\n      });\n      $('#idx').on('change', function(){\n      console.log('idx changed - 1');\n      var i = $('.Row').length;\n      var nxt = $('#idx').val();\n      if (nxt < i & nxt >0) {\n      $('#idx').val(nxt)\n      $('.Row').hide();\n      $('.Row').eq(0).show();\n      $('.Row').eq(nxt).show();\n      } else {\n      $('#idx').val(i)\n      }\n      console.log('idx changed - 2');\n      });\n      });\n      </script>\n      <style type='text/css'>\n      .Table\n      {\n      display: table;\n      }\n      .Title\n      {\n      display: table-caption;\n      text-align: center;\n      font-weight: bold;\n      font-size: larger;\n      background-color:#4C6F50;\n      color: #fff;\n      }\n      .Row\n      {\n      display: table-row;\n      }\n      .Row:nth-child(even) {\n        background-color: #56882433;\n      }\n      .Cell\n      {\n      display: table-cell;\n      border: solid;\n      border-width: thin;\n      padding-left: 5px;\n      padding-right: 5px;\n      vertical-align: top;\n      font-family: Arial, Helvetica, sans-serif;\n      font-size: 14px;\n      }\n      </style>\n      </head>\n      <body>\n      <div id='pageone' data-role='main' class='ui-content'>\n      \", file = myhtml, sep='\\n',append=FALSE)\n\n  html <- paste(\"<p><p><h1> Data Visualization & Exploration </h1>\n                <form>\n                <input type='button' id='onetoone' value='Show as Cards'>\n                <input type='button' id='aslist' class='onetoone' value='Show as List'>\n                </form>\n                <p>\n                \")\n  cat(html, file = myhtml, sep='\\n', append=TRUE)\n  # begin table\n  alt1 <- ifelse(is.null(y)== TRUE, \"\", \"<div class='Cell Title'> Dependent <br> Variable <br> Distribution </div>\")\n  html <- paste(\"<p><p>\n                <div class='Table'>\n                <div class='Row'>\n                <div class='Cell Title'> Variable </div>\n                <div class='Cell Title'> Distribution </div>\n                <div class='Cell Title'> Descriptive <br> Statistics</div>\n                <div class='Cell Title'> Outliers </div>\"\n                , alt1,\n                \"</div>\")\n  cat(html, file = myhtml, sep='\\n', append=TRUE)\n\n  #### determinate the type of each variable...\n  data_types <- sapply(sapply(data, class), whatVarType)\n  ln <- length(data)\n  ii <- 0\n  pb <- utils::txtProgressBar(min=0,max=ln,style=3)\n  for(x in names(data)) {\n\n    ## check if the value has at least more than one unique value...\n    if(length(unique(data[[x]])) < 2) {\n      message(paste(\"The variable\",x,\"has less than two unique values, so will not be included\"))\n    } else {\n\n      if(debug==TRUE) {\n        message(x)\n      } else {\n        pb <- utils::txtProgressBar(min=0,max=ln,style=3)\n      }\n\n      html <- paste(\"<div class='Row'><div class='Cell'><b>\",x,\"</b><p>\",xname[x],\"</p></div>\")\n\n      cat(html, file = myhtml, sep='\\n', append=TRUE)\n      #### initialize the first graph\n      imgname = paste(fig,\"/\",x, \"_1.png\",sep=\"\")\n      #imgsrc = paste(paste0(srcdir,\"/fig/\"),x, \"_1.png\",sep=\"\")\n      imgsrc = paste(\"fig/\",x, \"_1.png\",sep=\"\")\n      ### send the data with the type to generate the correct graph..\n      grDevices::png(imgname)\n      drawGraphOne(x, data[[x]], data_types[x])\n      grDevices::dev.off()\n      html <- paste0(\"<div class='Cell'><img class='origimg'  src='\",imgsrc,\"' height='150' width='150'><br></div>\")\n      cat(html, file = myhtml, sep='\\n', append=TRUE)\n\n      # second, show the statistics\n      html <- getStats(data[[x]],data_types[x])\n      cat(html, file = myhtml, sep='\\n', append=TRUE)\n\n      # third, determine the outliers\n      imgname = paste(fig,\"/\",x, \"_2.png\",sep=\"\")\n      if(data_types[x]==1) {\n        grDevices::png(imgname)\n        getOutlierGraph(data[[x]])\n        grDevices::dev.off()\n        html <- getOutliersHtml(x,data[[x]],srcdir)\n      } else {\n        html <- \"<div class='Cell'></div>\"\n      }\n      cat(html, file = myhtml, sep='\\n', append=TRUE)\n\n      # fourth, if y is assigned, make a corresponding plot\n      if(is.null(y)==FALSE) {\n        imgname = paste(fig,\"/\",x, \"_3.png\",sep=\"\")\n        #imgsrc = paste(paste0(srcdir,\"/fig/\"),x, \"_3.png\",sep=\"\")\n        imgsrc = paste(\"fig/\",x, \"_3.png\",sep=\"\")\n        grDevices::png(imgname)\n        ### scatter.smooth(data[[x]] ~ data[[y]])\n        #suppressWarnings(getScatterGraph(data,x,y,data_types[y]))\n        plot(getScatterGraph(data,x,y,data_types[y]))\n        grDevices::dev.off()\n        html <- paste0(\"<div class='Cell'><img class='origimg' src='\",imgsrc,\"' height='150' width='150'><br></div>\")\n        cat(html, file = myhtml, sep='\\n', append=TRUE)\n      }\n      html <- paste(\"</div>\")\n      cat(html, file = myhtml, sep='\\n', append=TRUE)\n\n      if(debug==FALSE) {\n        utils::setTxtProgressBar(pb,ii)\n        ii <- ii + 1\n      }\n    }\n  }\n  utils::setTxtProgressBar(pb,ln)\n  html <- paste(\"</div>\")\n  cat(html, file = myhtml, sep='\\n', append=TRUE)\n  # end table\n  html <- paste(\"</div>\n                <div data-role='popup' id='myContainer' style='display: none;'>\n                <img id='popup_img' src='' />\n                </div>\n                </div>\n                </div>\n                </div>\n                <p>\n                <div class='onetoone'>\n                <form id='myform2'>\n                <span> <input type='button' id='less' value=' << '> </span>\n                <span> <input id='idx' name='idx' value='1'></input></span>\n                <span> <input type='button' id='more' value=' >> '> </span>\n                </form>\n                </div>\n                <p>\n                </body></html>\n                \")\n  cat(html, file = myhtml, sep='\\n', append=TRUE)\n  ## call the default browser or the one which is open (if any)\n  browseURL(myhtml)\n}\n\n###################### END exploreData ###############\n\n\n############################################################################\n#####   TABLE 1                                                         ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-03-09                                       ####\n#####   Last Modified: 2020-11-03                                       ####\n############################################################################\n\n####################  FUNCTIONS  ###########################################\n#### Usage:\n####   x: character vector with the name of the variables\n####   y: the name of the strata variable (optional)\n####   rn: character vector with the text we want to replace the variable names\n####   data: the dataset to be used\n####   miss: include missing statistics: [0=none, 1=only for categorical variables, 2=for all variables]\n####   excel: export the table to excel [0=no, 1=yes]\n####   excel_file: the name of the excel file we want to save the table (optional)\n####\n###################\n\nTable1 <- function(x=NULL, y=NULL, rn=NULL, data=NULL, miss=3, catmiss=TRUE, formatted=TRUE, categorize=FALSE,\n                    factorVars=NULL, maxcat=10, delzero=TRUE, decimals=1, messages=TRUE, excel=0, excel_file=NULL,\n                    debug=FALSE) {\n  ### define sub-functions\n  Del <- NULL\n  Pop <- NULL\n  n <- NULL\n  g1 <- function(var)c(Mean=mean(var,na.rm=TRUE), SD=stats::sd(var,na.rm=TRUE))\n  g2 <- function(var)c(Median=stats::median(var,na.rm=TRUE), IQR=stats::quantile(var,c(0.25,0.75),na.rm=TRUE))\n  msg <- NULL\n  \n  ### function for transforming variables to factors\n  setFactors <- function(data=data, factorVars=factorVars, catmiss=catmiss, maxcat=maxcat) {\n    if(is.null(factorVars)==TRUE) {\n      aa <- sapply(sapply(data, unique), length)\n      factorVars <- names(which(aa <= maxcat))\n    }\n    for (v in factorVars) {\n      ct <- ifelse( ((is.null(factorVars)==FALSE & (v %in% factorVars)) | (is.null(factorVars)==TRUE & length(unique(data[[v]])) <= maxcat)),1,0)\n      if (ct == 1) {\n        data[[v]] <- factor(data[[v]])\n        if(catmiss == TRUE & sum(is.na(data[[v]])==TRUE) > 0) {\n          data[[v]] <- factor(data[[v]],levels=c(levels(data[[v]]),\"Missing\"))\n          data[[v]][which(is.na(data[[v]])==TRUE)] <- \"Missing\"\n        }\n      }\n    }\n    return(data)\n  }\n  ### proceed to convert varibles to factors\n  if (categorize == TRUE | is.null(factorVars)==FALSE ) {\n    data <- setFactors(data, factorVars, catmiss, maxcat)\n  }\n  \n  getSimpleTable  <- function(x=x, rn=rn, data=data, miss=miss, catmiss=catmiss,formatted=formatted,\n                              categorize=categorize,maxcat=maxcat, delzero=delzero) {\n    if (is.null(x)==TRUE) { x <- names(data)}\n    if (is.null(rn)==TRUE) { rn <- x}\n    ln <- length(x)\n    pb <- utils::txtProgressBar(min=0,max=ln,style=3)\n    msg <- NULL\n    ### define the column names\n    tableaaaa <- cbind(Del=\"Del\",V1=\"Variables\",V2=\"Categories\",n=\"n\",\"Population\")\n    tablebbbb <- cbind(Del=\"Del\",V1=\"Variables\",V2=\"Categories\",n=\"n\",val1=\"val1\",val2=\"val2\",val3=\"val3\")\n    tbl1 <- cbind(0,\"Individuals\",\"n\",n=1, nrow(data))\n    tbl2 <- cbind(0,\"Individuals\",\"n\",n=1, nrow(data),NA,NA)\n    tableaaaa <- rbind(tableaaaa,tbl1)\n    tablebbbb <- rbind(tablebbbb,tbl2)\n    q <- 1\n    n <- 1\n    ii <- 1\n    for (v in x)\n    {\n      if (v %in% names(data)) {\n        ### define if the actual variable has to be treated as numeric or factor\n        ct <- ifelse(is.numeric(data[[v]])==TRUE & categorize==TRUE &\n                       ((is.null(factorVars)==FALSE & (v %in% factorVars)) |\n                          (is.null(factorVars)==TRUE & length(unique(data[[v]])) <= maxcat)),1,0)\n        ### treat as numeric\n        if (length(unique(data[v]))==0) {\n          if (messages==TRUE) {\n            msg <- c(msg, paste(\"The variable\",v,\"has no data; avoided\"))\n          }\n        } else if (inherits(data[[v]], \"Date\")==TRUE) {\n          if (messages==TRUE) {\n            msg <- c(msg, paste(\"The variable\",v,\"is a date. Dates are not allowed in Table1; avoided\"))\n          }\n        } else if (is.numeric(data[[v]])==TRUE & ct==0) {\n          ## report mean and standard deviation\n          t_n <- g1(data[[v]])\n          tp <- paste(format(round(t_n[1],decimals),nsmall=1,big.mark=\",\"),\" (\", format(round(t_n[2],decimals),nsmall=1,big.mark=\",\"),\")\",sep=\"\")\n          tbl1 <- cbind(0,rn[q],\"Mean (SD)\",n=1, tp)\n          tbl2 <- cbind(0,rn[q],\"Mean (SD)\",n=1,t_n[1],t_n[2],NA)\n          tableaaaa <- rbind(tableaaaa,tbl1)\n          tablebbbb <- rbind(tablebbbb,tbl2)\n          ## report median and Interquartile ranges (25%,75%)\n          t_n <- g2(data[[v]])\n          tp <- paste(format(round(t_n[1],decimals),nsmall=1,big.mark=\",\"),\" (\", format(round(t_n[2],decimals),nsmall=1,big.mark=\",\"),\"-\", format(round(t_n[3],decimals),nsmall=1,big.mark=\",\"), \")\",sep=\"\")\n          tbl1 <- cbind(0,rn[q],\"Median (IQR)\",n=2, format(tp,big.mark=\",\"))\n          tbl2 <- cbind(0,rn[q],\"Median (IQR)\",n=2,t_n[1],t_n[2],t_n[3])\n          tableaaaa <- rbind(tableaaaa,tbl1)\n          tablebbbb <- rbind(tablebbbb,tbl2)\n          ## report number and percent of missing\n          if (miss >= 1) {\n            datams <- subset(data,is.na(data[[v]])==TRUE)\n            if (nrow(datams)>0) {\n              data$cnt <- 1\n              datams$cnt <- 1\n              t_n <- table(data$cnt)\n              t_m <- sum(datams$cnt)\n              tp <- paste(format(t_m,big.mark=\",\"),\" (\",format(round((t_m/t_n)*100,decimals),nsmall=1,big.mark=\",\"),\"%)\",sep=\"\")\n              tbl1 <- cbind(0,rn[q],\"Missing (%)\",n=3, tp)\n              tbl2 <- cbind(0,rn[q],\"Missing (%)\",n=3, t_m, (t_m/t_n)*100, NA)\n            } else {\n              tbl1 <- cbind(1,rn[q],\"Missing (%)\",n=3, \" -- \")\n              tbl2 <- cbind(1,rn[q],\"Missing (%)\",n=3, NA, NA, NA)\n            }\n            tableaaaa <- rbind(tableaaaa,tbl1)\n            tablebbbb <- rbind(tablebbbb,tbl2)\n          }\n        } else {\n          t_n <- table(data[[v]])\n          ttotal <- sum(t_n)\n          nm <- row.names(t_n)\n          for (f in 1:length(nm)) {\n            del1 <- ifelse(length(nm)==2 & (nm[f]==\"No\" | nm[f]==\"no\" | nm[f]==0 | nm[f]==\"0\" | nm[f]==\"None\" | nm[f]==\"none\"),1,0)\n            tp <- t_n[f] / ttotal * 100\n            pct <- paste(format(round(t_n[f],decimals),nsmall=0,big.mark=\",\"),\" (\", format(round(tp,decimals),nsmall=1,big.mark=\",\"), \"%)\",sep=\"\")\n            tbl1 <- cbind(del1,rn[q],nm[f],n=f, pct)             ########### delete rows 0/1 !!!!!!!!!\n            tbl2 <- cbind(del1,rn[q],nm[f],n=f, t_n[f], tp, NA)  ########### delete rows 0/1 !!!!!!!!!\n            tableaaaa <- rbind(tableaaaa,tbl1)\n            tablebbbb <- rbind(tablebbbb,tbl2)\n          }\n          if (miss >= 2 & catmiss==FALSE ) {\n            datams <- subset(data,is.na(data[[v]])==TRUE)\n            if (nrow(datams)>0) {\n              data$cnt <- 1\n              datams$cnt <- 1\n              t_n <- table(data$cnt)\n              t_m <- sum(datams$cnt)\n              tp <- paste(format(t_m,big.mark=\",\"),\" (\",format(round((t_m/t_n)*100,decimals),nsmall=1,big.mark=\",\"),\"%)\",sep=\"\")\n              tbl1 <- cbind(0,rn[q],\"Missing (%)\",n=f, tp)\n              tbl2 <- cbind(0,rn[q],\"Missing (%)\",n=f, t_m, (t_m/t_n)*100, NA)\n            } else {\n              tbl1 <- cbind(1,rn[q],\"Missing (%)\",n=f, \" -- \")\n              tbl2 <- cbind(1,rn[q],\"Missing (%)\",n=f, NA, NA, NA)\n            }\n            tableaaaa <- rbind(tableaaaa,tbl1)\n            tablebbbb <- rbind(tablebbbb,tbl2)\n          }\n        }\n      } else {\n        if (messages==TRUE) {\n          msg <- c(msg, paste(\"The variable\",v,\"doesn't exists in the dataset; avoiding\"))\n        }\n      }\n      q <- q + 1\n      if(debug==FALSE) {\n        utils::setTxtProgressBar(pb,ii)\n        ii <- ii + 1\n      } else {\n        message(v)\n      }\n    }\n    if(formatted==TRUE) {\n      return(tableaaaa)\n    } else {\n      return(tablebbbb)\n    }\n    close(pb)\n  }\n  \n  pvals <- function(x=x,y=y,rn=rn,data=data,categorize=categorize,maxcat=maxcat) {\n    ptab <- NULL\n    if (is.null(y)==FALSE) {\n      if (y %in% names(data)) {\n        if (is.null(x)==TRUE) { x <- names(data)}\n        if (is.null(rn)==TRUE | length(rn)<2) {rn <- x}\n        q <- 1\n        ptab <- cbind(V=\"Variables\",pval=\"pval\", n=\"n\")\n        \n        ln <- length(x)\n        ii <- 0\n        pb <- utils::txtProgressBar(min=0,max=ln-1,style=3)\n        \n        for (v in x) {\n          if (v %in% names(data)) {\n            ct <- ifelse(is.numeric(data[[v]])==TRUE & categorize==TRUE & length(unique(data[[v]])) <= maxcat,1,0)\n            if (is.numeric(data[[y]])==TRUE & categorize==TRUE & length(unique(data[[y]])) <= maxcat) {\n              data[[y]] <- as.factor(data[[y]])\n            } else if (is.numeric(data[[y]])==TRUE) {\n              if (messages==TRUE) {\n                msg <- c(msg, paste(\"The variable\",y,\"is not a factor. Please convert to factor or change the 'categorize' flag to TRUE.\"))\n              }\n              pval <- \"Please rerun!!!\"\n            }\n            if (is.numeric(data[[v]])==TRUE & length(unique(data[[v]])) > 1 & ct == 0) {\n              ### first check for homoscedasticity\n              tryCatch({\n                if (stats::bartlett.test(data[[v]], data[[y]])[3] >= 0.05) {\n                  pval <- suppressMessages(round(as.numeric(suppressMessages(car::Anova(stats::lm(data[[v]] ~ data[[y]])))[1, 4]), 3))\n                } else {\n                  pval <- suppressMessages(round(as.numeric(suppressMessages(car::Anova(stats::lm(data[[v]] ~ data[[y]]), white.adjust = TRUE))[1, 3]), 3))\n                }\n              }, warning = function(w) {\n                suppressWarnings(w)\n                #ww <- \"suppress warnings\"\n              }, error = function(e) {\n                pval <- \"---\"\n              })\n            } else if (length(unique(data[[v]]))==1) {\n              pval <- NA\n            } else {\n              if(length(unique(data[[v]])) < 15) {\n                if (min(table(data[[v]],data[[y]])) > 5) {\n                  pval <- round(as.numeric(stats::chisq.test(data[[v]],data[[y]])$p.val),3)\n                } else {\n                  if(min(table(data[[v]],data[[y]]))==0) {\n                    #in cases where there are cells with zero, we use Fisher's exact test\n                    tryCatch(\n                      pval <- round(as.numeric(stats::fisher.test(data[[v]],data[[y]], workspace=1e9)$p.val),3),\n                      error = function(e) {msg <- c(msg,paste0(\"Unable to calcualte the Fisher test for variables \",v,\" and \",y))})\n                  } else {\n                    pval <- round(as.numeric(stats::kruskal.test(data[[v]],data[[y]], workspace=1e9)$p.val),3)\n                  }\n                }\n              } else {\n                pval <- NA\n              }\n            }\n            ptab <- rbind(ptab,cbind(V=rn[q],pval=pval,n=2))\n          }\n          if(debug==FALSE) {\n            utils::setTxtProgressBar(pb,ii)\n            ii <- ii + 1\n          }\n          q <- q + 1\n        }\n      }\n    }\n    return(ptab)\n  }\n  ####################### Begin analysis\n  ##### check for x's witch have one unique values, get them out.\n  vv <- NULL\n  j <- 0\n  jj <- NULL\n  for(v in x) {\n    if(length(unique(data[[v]])) < 2) {\n      vv <- c(vv,v)\n      j <- j + 1\n      jj <- c(jj,j)\n    }\n  }\n  \n  if (length(vv)>0) {\n    warning(paste(\"The following variables have unique values and will not be included in the analysis:\",vv))\n    x <- setdiff(x, vv)\n    if(is.null(rn)==FALSE & length(jj)>0) {\n      rn <- rn[-jj]\n    }\n  }\n  \n  ##### if y is null then make a simple table\n  tabaaa1 <- getSimpleTable(x=x, rn=rn, data=data, miss=miss, catmiss=catmiss,formatted=formatted,categorize=categorize,maxcat=maxcat, delzero=delzero)\n  tabaaa1 <- as.data.frame(tabaaa1)\n  ############################  CHANGE TO 5 !!!!!!!!!!!!!!\n  if(length(tabaaa1) > 5) {\n    names(tabaaa1) <- c(\"Del\",\"V1\",\"V2\",\"n\",\"Pop\",\"pop2\",\"pop3\")\n  } else {\n    names(tabaaa1) <- c(\"Del\",\"V1\",\"V2\",\"n\",\"Pop\")\n  }\n  ##### if y has two levels, then make a compound comparison\n  if (is.null(y)==FALSE){\n    if (y %in% names(data)) {\n      if (is.factor(data[[y]])==FALSE) {\n        if (length(levels(factor(data[[y]]))) > 8) {\n          if (messages==TRUE) {\n            message(\"The dependent variable has more than 8 levels, table too large!\")\n          }\n        } else if(min(table(data[[y]]))==0) {\n          message(\"The dependent variable has one or more levels with no individuals assigned!\")\n        } else {\n          data[[y]] <- factor(data[[y]])\n        }\n      }\n      if (length(levels(data[[y]])) >= 2) {\n        for (lv in levels(data[[y]])) {\n          dtsub <- subset(data, data[[y]]==lv)\n          tab <- getSimpleTable(x=x, rn=rn, data=dtsub, miss=miss, catmiss=catmiss, formatted=formatted,categorize=categorize,maxcat=maxcat, delzero=delzero)\n          tab <- data.frame(tab)\n          ############################  \n          if(length(tab) > 5) {\n            names(tab) <- c(\"Del\",\"V1\",\"V2\",\"n\",paste0(lv,\"_1\"),paste0(lv,\"_2\"),paste0(lv,\"_3\"))\n          } else {\n            names(tab) <- c(\"Del\",\"V1\",\"V2\",\"n\",lv)\n          }\n          ############################  \n          tab[1,5] <- lv\n          tabaaa1 <- base::merge(tabaaa1, tab, all.x=TRUE)\n        }\n        # what to do with dichotomous variables? We remove the \"Zero\" label\n        # clean unnecesary rows\n        if (delzero == TRUE) {\n          tabaaa1 <- tabaaa1[tabaaa1$Del==0,]\n        }\n        ### calculate the p-value\n        ptab <- data.frame(pvals(x=x,y=y,rn=rn,data=data,categorize=categorize,maxcat=maxcat))\n        names(ptab) <- c(\"V1\",\"pval\",\"n\")\n        tabaaa1 <- base::merge(tabaaa1, ptab,all.x=TRUE)\n        tabaaa1 <- tabaaa1[tabaaa1$Pop != \" -- \",]\n      }\n    }\n  }\n  \n  tabaaa1$n <- NULL\n  tabaaa1$Del <- NULL\n  ### format the table for printing\n  n <- ncol(tabaaa1)\n  names(tabaaa1)[1] <- \"Variables\"\n  names(tabaaa1)[2] <- \"\"\n  names(tabaaa1)[3] <- \"Population\"\n  names(tabaaa1)[n] <- \"p-value\"\n  tabaaa1[,n] <- as.character(tabaaa1[,n])\n  tabaaa1[,n] <- ifelse(is.na(tabaaa1[,n]),\"\",tabaaa1[,n])\n  tabaaa1[,n] <- ifelse(tabaaa1[,n]=='0',\"<0.001\",tabaaa1[,n])\n  \n  ##### check for export to excel\n  if (excel==1) {\n    writexl::write_xlsx(tabaaa1,excel_file)\n    return(tabaaa1)\n  } else {\n    return(tabaaa1)\n  }\n}\n\n########################## END Table1 ###############\n\n\n############################################################################\n#####   TEST & TRAIN DATASET GENERATION                                 ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-08-17                                       ####\n#####   Last Modified: 2020-11-03                                       ####\n############################################################################\n\ntrain_test <- function(data=NULL,train_name=NULL,test_name=NULL,prop=NULL,seed=123,tableone=FALSE)\n{\n  pval <- NULL\n  checkTrainTest <- function(train=NULL,test=NULL) {\n    train[[\"traintest_ind_\"]] <- 1\n    test[[\"traintest_ind_\"]] <- 2\n    df <- rbind(train, test)\n    tab <- Table1(data=df, y=\"traintest_ind_\",messages = FALSE)\n    vars <- subset(tab, pval < 0.05)$V1\n    vars <- setdiff(vars,\"traintest_ind_\")\n    if (length(vars)==0) {\n      message(\" \")\n      message(\"You got a perfectly balanced training and test datasets\")\n      message(\" \")\n    } else {\n      message(\"WARNING: The following variables are not balanced between the training and test datasets:\")\n      for (v in vars) { message(paste(\"*\",v)) }\n      message(\"You can try to change the seed value until you get a balanced partition.\")\n      message(\"Alternatively, you can ommit this warning and exclude those variables from your model\")\n      message(\" \")\n    }\n    return(tab)\n  }\n  nm <- 1\n  ttenv = as.environment(nm)\n  ## set the seed to make your partition reproductible\n  set.seed(seed)\n  smp_size <- floor(prop * nrow(data))\n  train_ind <- sample(seq_len(nrow(data)), size = smp_size)\n  assign(train_name, data[train_ind, ], envir=ttenv)\n  assign(test_name, data[-train_ind, ], envir=ttenv)\n  message(paste(\"Dataset partitioned into:\"))\n  message(paste(\" + Train dataset:\", train_name))\n  message(paste(\" + Test dataset:\", test_name))\n  if(tableone==TRUE) {\n    tab <- checkTrainTest(get(train_name),get(test_name))\n    tab <- tab[tab[,1]!=\"traintest_ind_\",]\n    names(tab)[4] <- train_name\n    names(tab)[5] <- test_name\n    return(tab)\n  }\n}\n\n\n######################### END train_test ###############\n\n\n############################################################################\n#####   TABLE 2                                                         ####\n#####   Description: calculates the Odds/Hazard ratios and their        ####\n#####     confidence intervals from a given model\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-03-09                                       ####\n#####   Last Modified: 2018-04-16                                       ####\n############################################################################\n\nTable2 <- function(mod, rv=NULL,level=0.95, decimals=3) {\n  alpha <- 1-level\n  msm <- suppressMessages(summary(mod))\n  if(rlang::has_name(msm,\"coefficients\")==TRUE) {\n    msm <- msm$coefficients\n  } else if(rlang::has_name(msm,\"coef\")==TRUE) {\n    msm <- msm$coef\n  }\n  if(\"coxph\" %in% class(mod)) {\n    exp_coef <- msm[,1]\n    dd <- suppressMessages(exp(stats::confint(mod, level=level)))\n    dd1 <- round(dd[,1],decimals)\n    dd2 <- round(dd[,2],decimals)\n    p_value <- round(msm[,ncol(msm)],decimals)\n  } else {\n    ciz <- stats::qnorm(1-(alpha/2))\n    exp_coef <- exp(msm[, 1])\n    se_exp_coef <- msm[,2] * exp_coef\n    dd1 <- round(exp_coef - ciz * se_exp_coef, decimals)\n    dd2 <- round(exp_coef + ciz * se_exp_coef, decimals)\n    exp_coef <- round(exp_coef, decimals)\n    z<- abs((exp_coef-1)/se_exp_coef)\n    p_value <- round(2*(1-stats::pnorm(z)), decimals)\n  }\n  tb <- data.frame(cbind(Estimate=exp_coef,'CI_lo'=dd1,'CI_hi'=dd2,'p value'=p_value))\n  if (is.null(rv)==FALSE) {\n    row.names(tb) <- rv\n  } else {\n    row.names(tb) <- names(mod$coefficients)\n  }\n  return(tb)\n}\n\n############################################################################\n#####   TABLE2 WITH FORESTPLOT                                          ####\n#####   Description: Generates a publication ready version of a model   ####\n#####      risk table with a forestplot graph inside it                 ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2018-05-17                                       ####\n############################################################################\nTable2.forestplot <- function(mod, nr=NULL) {\n  opar <- graphics::par(no.readonly = TRUE)\n  on.exit(graphics::par(opar))\n  tryCatch({tbA <- Table2(mod)},\n           error=function(cond) {\n             message(\"This model type is not supported !\")\n             return(NA)\n           })\n  if(exists(\"tbA\")) {\n    ## max value for x axis\n    xmax <- max(tbA[,3])\n    if(xmax < 5) {\n      #axis(1, seq(0,xmax,by=.5), cex.axis=.5)\n     rh <- 12\n    } else {\n      rh <- 18\n    }\n    colnames(tbA) <- c(\"coef\",\"ci_low\",\"ci_high\",\"p_value\")\n    j <- nrow(tbA)\n    nm <- row.names(tbA)\n    rowseq <- seq(nrow(tbA),1)\n    graphics::par(mai=c(1,0,0,0),new=FALSE)\n    graphics::plot(tbA$coef, rowseq, pch=15,\n         xlim=c(-10,rh), ylim=c(0,j+3),\n         xlab='', ylab='', yaxt='n', xaxt='n',\n         bty='n')\n    for (i in 1:j) {\n      graphics::abline(h=i-0.5,lwd=1, lty=3, col=\"gray\")\n    }\n    graphics::par(new=TRUE)\n    graphics::plot(tbA$coef, rowseq, pch=15,\n         xlim=c(-10,rh), ylim=c(0,j+3),\n         xlab='', ylab='', yaxt='n', xaxt='n',\n         bty='n')\n    graphics::axis(1, seq(0,xmax,by=.5), cex.axis=.5)\n    graphics::segments(1,-1,1,j, lty=3)\n    graphics::segments(tbA$ci_low, rowseq, tbA$ci_hi, rowseq)\n    graphics::mtext('Lower risk',1, line=2.5, at=0, cex=.5, font=2)\n    graphics::mtext('Higher risk',1.5, line=2.5, at=2, cex=.5, font=2)\n    if (is.null(nr)) {\n      nr <- data.frame(vars=names(mod$coefficients))\n      col2 <- as.character(gsub(x=nr$vars, pattern=paste(names(mod$xlevels),collapse=\"|\"),replacement=\" \"))\n      col3 <- data.frame(vars=as.character(NULL),col3=as.character(NULL))\n      for(n in names(mod$xlevels)) {\n        col3 <- rbind(col3, cbind(vars=paste(n,levels(mod$data[[n]])[2],sep=\"\"),col3=n))\n      }\n      nr$col1 <- ifelse(nr$vars %nin% setdiff(names(mod$coefficients),names(mod$data)),as.character(nr$vars),'')\n      nr$col2 <- ifelse(nr$vars %nin% col2, col2, \" \")\n      nr[1,\"col1\"] <- ifelse(nr[1,\"vars\"]==\"(Intercept)\",\"(Intercept)\",nr[1,\"vars\"])\n      nr$col1 <- ifelse(nr$vars %in% col3, col3, nr$col1)\n      nr <- merge(nr,col3, x.all=TRUE)\n      nr$col1 <- ifelse(is.na(nr$col3)==TRUE,nr$col1,as.character(nr$col3))\n      nr$col1 <- ifelse(grepl(\":\",nr$vars),nr$vars,nr$col1)\n    } else {\n      nr <- data.frame(vars=nr)\n      if (length(nm)==nrow(nr)) {\n        nr <- cbind(nm,nr)\n        colnames(nr) <- c(\"vars\",\"col1\",\"col2\")\n      } else {\n        return(\"The number of variables in the table of names (nr) you give is not equal to the number of variables in the model.\n               Please check the names you entered in the table.\")\n      }\n    }\n    ### this part writes the variable titles\n    graphics::text(-10,j+2, \"Variables\", cex=.75, font=2, pos=4)\n    graphics::abline(h=j+1, col=\"gray\", lwd=1.5, lty=1)\n    graphics::text(-10,rowseq, nr[,2], cex=.75, pos=4, font=3)\n    ### and this writes the categories for nominal variables\n    graphics::text(-6,rowseq, nr[,3], cex=.75, pos=4)\n    graphics::text(-3,j+2, \"Odds Ratio (95% CI)\", cex=.75, font=2, pos=4)\n    t3 <- ifelse(!is.na(tbA$coef),\n                 with(tbA, paste(format(coef,nsmall = 3,digits = 3),' (',format(ci_low,nsmall = 3,digits = 3),'-',format(ci_high,nsmall = 3,digits = 3),')',sep='')), '')\n    graphics::text(xmax,rowseq, t3, cex=.75, pos=4, bg=\"lightgreen\")\n    graphics::text(xmax+5,j+2, \"P Value\", cex=.75, font=2, pos=4)\n    t4 <- ifelse(!tbA$p_value==0, paste0(\" \",format(tbA$p_value,nsmall = 3,digits = 3)), '<0.001')\n    graphics::text(xmax+5,rowseq, t4, cex=.75, pos=4)\n    graphics::box(which = \"outer\",col=\"darkgray\",lwd=3)\n  }\n  graphics::par(mai=c(1,1,1,1),new=FALSE)\n}\n\n############################################################################\n#####   CALCULATE CONFIDENCE INTERVALS FOR MEANS                        ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-08-24                                       ####\n############################################################################\nMeanCI <- function(x,round=3) {\n  m <- mean(x,na.rm=TRUE)\n  s <- stats::sd(x,na.rm=TRUE)\n  ci <- 1.96 * (s/sqrt(length(x)))\n  CImin <- m - ci\n  CImax <- m + ci\n  return(c(mean=round(m,round),CImin=round(CImin,round),CImax=round(CImax,round)))\n}\n\n############################################################################\n#####   CALCULATE CONFIDENCE INTERVALS FOR PROPORTIONS                  ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-08-24                                       ####\n############################################################################\nPropCI <- function(x,round=3,multi=100,ref=2) {\n  recode <- function(x,ref) {\n    y <- x\n    if (ref==2) {\n      y[which(x==min(x))] <- 0\n      y[which(x==max(x))] <- 1\n    } else {\n      y[which(x==max(x))] <- 0\n      y[which(x==min(x))] <- 1\n    }\n    return(y)\n  }\n  if (is.factor(x)==TRUE && length(levels(x))==2) {\n    p <- levels(x)[ref]\n    y <- recode(as.numeric(x),ref)\n  } else if (is.numeric(x)==TRUE && length(levels(factor(x)))==2) {\n    p <- ifelse(ref==2,max(x),min(x))\n    y <- recode(x,ref)\n  } else if (length(levels(factor(x)))==2) {\n    p <- levels(factor(x))[ref]\n    y <- recode(as.numeric(factor(x)),ref)\n  } else {\n    return(\"The variable must be dichotomic\")\n  }\n  freq <- (mean(y,na.rm=TRUE))\n  CI <- 1.96 * sqrt((freq * (1-freq))/length(y))\n  CImin <- (freq - CI)*multi\n  CImax <- (freq + CI)*multi\n  return(c(var=p,freq=round(freq*multi,round),CImin=round(CImin,round),CImax=round(CImax,round)))\n}\n\n############################################################################\n#####   GENERATE A TABLE WITH VALIDITY TESTS                            ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-08-17                                       ####\n############################################################################\n\n################# Validity Test #########################################\n#\n#                    Observed\n#                              +                  -\n#          -----------------------------------------\n# Predicted   +    TP                FP        |     PPV\n#                                            a                   b         |  e (e1-e2)\n#                                                                             |\n#                                                             |\n#                         -    FN       TN        |     NPV\n#                                c        d         |  f (f1-f2)\n#                      ----------------------------------------\n#\n#                        Sensitivity Specificity  |  Prevalence\n#                          g (g1-g2)  h (h1-h2)   |  i (i1-i2)\n#\n#\n#       Chi-square\n#       Corrected Chi-square\n#       Error: (FP+FN)/(TP+FP+FN+TN)\n#       Accuracy: (TP+TN)/(TP+FP+FN+TN)\n#       Precision: TP/(TP+FP)\n#       Recall: TP/(TP+FN)\n#\n#       Harmonic mean of precision and recall (F1-Score):\n#        f1-Score: 2 * (Precision * Recall)/(Precision + Recall)\n#\n#####################################################################\n\nValidityTest <- function (a, b, c, d, multi = 100, caption = \"Validity of the Model/Screening\")\n{\n\n  proportionCI <- function(p, n, multi = 100, prob = 0.95, dec = 2) {\n    alpha <- ifelse(prob != 0.95,0.01,0.05)\n    ci <- Hmisc::binconf(p,n,alpha=alpha,method=\"wilson\")\n    pci = paste(round(ci[1] * multi, dec), \" (\",\n                round(ci[2] * multi, dec), \"-\",\n                round(ci[3] * multi, dec), \")\",\n                sep = \"\")\n    return(pci)\n  }\n\n  lr.ci <- function( a,b,c,d, sig.level=0.95 ) {\n    ### Positive and negative likelihood ratios with their 95% CI...\n    alpha <- 1 - sig.level\n    spec <- d/(b+d)\n    sens <- a/(a+c)\n    lr.pos <- sens/(1 - spec)\n    if ( a != 0 & b != 0 ) {\n      sigma2 <- (1/a) - (1/(a+c)) + (1/b) - (1/(b+d))\n      lower.pos <- lr.pos * exp(-stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n      upper.pos <- lr.pos * exp(stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n    } else if ( a == 0 & b == 0 ) {\n      lower.pos <- 0\n      upper.pos <- Inf\n    } else if ( a == 0 & b != 0 ) {\n      a.temp <- (1/2)\n      spec.temp <- d/(b+d)\n      sens.temp <- a.temp/(a+c)\n      lr.pos.temp <- sens.temp/(1 - spec.temp)\n      lower.pos <- 0\n      sigma2 <- (1/a.temp) - (1/(a.temp+c)) + (1/b) - (1/(b+d))\n      upper.pos <- lr.pos.temp * exp(stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n    } else if ( a != 0 & b == 0 ) {\n      b.temp <- (1/2)\n      spec.temp <- d/(b.temp+d)\n      sens.temp <- a/(a+c)\n      lr.pos.temp <- sens.temp/(1 - spec.temp)\n      sigma2 <- (1/a) - (1/(a+c)) + (1/b.temp) - (1/(b.temp+d))\n      lower.pos <- lr.pos.temp * exp(-stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n      upper.pos <- Inf\n    } else if ( (a == (a+c)) & (b == (b+d)) ) {\n      a.temp <- a - (1/2)\n      b.temp <- b - (1/2)\n      spec.temp <- d/(b.temp+d)\n      sens.temp <- a.temp/(a+c)\n      lr.pos.temp <- sens.temp/(1 - spec.temp)\n      sigma2 <- (1/a.temp) - (1/(a.temp+c)) + (1/b.temp) - (1/(b.temp+d))\n      lower.pos <- lr.pos.temp * exp(-stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n      upper.pos <- lr.pos.temp * exp(stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n    }\n    lr.neg <- (1 - sens)/spec\n    if ( c != 0 & d != 0 ) {\n      sigma2 <- (1/c) - (1/(a+c)) + (1/d) - (1/(b+d))\n      lower.neg <- lr.neg * exp(-stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n      upper.neg <- lr.neg * exp(stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n    } else if ( c == 0 & d == 0 ) {\n      lower.neg<- 0\n      upper.neg <- Inf\n    } else if ( c == 0 & d != 0 ) {\n      c.temp <- (1/2)\n      spec.temp <- d/(b+d)\n      sens.temp <- a/(a+c.temp)\n      lr.neg.temp <- (1 - sens.temp)/spec.temp\n      lower.neg <- 0\n      sigma2 <- (1/c.temp) - (1/(a+c)) + (1/d) - (1/(b+d))\n      upper.neg <- lr.neg.temp * exp(stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n    } else if ( c != 0 & d == 0 ) {\n      d.temp <- (1/2)\n      spec.temp <- d.temp/(b+d)\n      sens.temp <- a/(a+c)\n      lr.neg.temp <- (1 - sens.temp)/spec.temp\n      sigma2 <- (1/c) - (1/(a+c)) + (1/d.temp) - (1/(b+d))\n      lower.neg <- lr.neg.temp * exp(-stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n      upper.neg <- Inf\n    } else if ( (c == (a+c)) & (d == (b+d)) ) {\n      c.temp <- c - (1/2)\n      d.temp <- d - (1/2)\n      spec.temp <- d.temp/(b+d)\n      sens.temp <- a/(a+c.temp)\n      lr.neg.temp <- (1 - sens.temp)/spec.temp\n      sigma2 <- (1/c.temp) - (1/(a+c)) + (1/d.temp) - (1/(b+d))\n      lower.neg <- lr.neg.temp * exp(-stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n      upper.neg <- lr.neg.temp * exp(stats::qnorm(1-(alpha/2))*sqrt(sigma2))\n    }\n    list(\n      lr.pos=lr.pos, lower.pos=lower.pos, upper.pos=upper.pos,\n      lr.neg=lr.neg, lower.neg=lower.neg, upper.neg=upper.neg\n    )\n  }\n\n  ppv <- proportionCI(a, a + b, multi)\n  npv <- proportionCI(d, c + d, multi)\n  sensit <- proportionCI(a, c + a, multi)\n  specif <- proportionCI(d, b + d, multi)\n  prev <- proportionCI(a + c, (a + b + c + d), multi)\n  er <- proportionCI(b + c, (a + b + c + d), multi)\n  acc <- proportionCI(a + d, (a + b + c + d), multi)\n  prec <- proportionCI(a, (a + b), multi)\n  recall <- proportionCI(a, (a + c), multi)\n  f1 <- proportionCI(2 * ((a/(a + b)) * (a/(a + c))), ((a/(a + b)) + (a/(a + c))), multi)\n  #Odds ratios\n  odds <- ((a/c)/(b/d))\n  oddsci <- 1.96 * sqrt((1/a)+(1/b)+(1/c)+(1/d))\n  oddsratio <- paste(round(odds,2), \" (\", round(exp(log(odds)-oddsci),2), \"-\",round(exp(log(odds)+oddsci),2),\")\",sep=\"\")\n  #False positive rate = type I error= 1 - specificity\n  fpr <- proportionCI(b, (d + b), multi)\n  #False negative rate = type II error= 1 - sensitivity\n  fnr <- proportionCI(c, (a + c), multi)\n  #Likelihood ratio positive = sensitivity / (1 - specificity)\n  # (a/(c+a) / b/(d+b))\n  lr <- lr.ci(a,b,c,d,sig.level=0.95)\n  plr1 <- paste(round(lr$lr.pos,2), \" (\", round(lr$lower.pos,2),\"-\",round(lr$upper.pos,2),\")\",sep=\"\")\n  #Likelihood ratio negative = (1 - sensitivity) / specificity\n  # (c/(a+c) / d/(b+d))\n  #nlr <- round((c*(b+d))/(d*(a+c)),2)\n  #nlr <- ((c*(b+d))/(d*(a+c)))\n  nlr1 <-  paste(round(lr$lr.neg,2), \" (\", round(lr$lower.neg,2),\"-\",round(lr$upper.neg,2),\")\",sep=\"\")\n  x <- matrix(c(a, b, c, d), byrow = TRUE, 2, 2)\n  csq <- tryCatch({\n    warning(stats::chisq.test(x))\n  }, warning = function(w) {\n    message(\"Using simulated p-value! - \", conditionMessage(w))\n    stats::chisq.test(x, simulate.p.value = TRUE)\n  })\n  xsq <- round(csq$statistic, 2)\n  pval <- round(csq$p.value, 2)\n  vars <- cbind(\"\", \"Observed\", \"\", \"\")\n  vars <- rbind(vars, cbind(\"\", \"+\", \"-\", \"\"))\n  vars <- rbind(vars, cbind(\"Expected\", \"(TP)\", \"(FP)\", \"PPV\"))\n  vars <- rbind(vars, cbind(\"+\", a, b, ppv))\n  vars <- rbind(vars, cbind(\"\", \"(FN)\", \"(TN)\", \"NPV\"))\n  vars <- rbind(vars, cbind(\"-\", c, d, npv))\n  vars <- rbind(vars, cbind(\"\", \"Sensitivity\", \"Specificity\",\n                            \"Prevalence\"))\n  vars <- rbind(vars, cbind(\"\", sensit, specif, prev))\n  vars <- rbind(vars, cbind(\"\", \"\", \"\", \"\"))\n  vars <- rbind(vars, cbind(\"Chi-square (p-value)\", paste(xsq,\n                                                          \" (\", pval, \")\", sep = \"\"), \"\", \"\"))\n  vars <- rbind(vars, cbind(\"Error\", er, \"\", \"\"))\n  vars <- rbind(vars, cbind(\"Accuracy\", acc, \"\",\n                            \"\"))\n  vars <- rbind(vars, cbind(\"Precision\", prec, \"(Same as PPV)\",\n                            \"\"))\n  vars <- rbind(vars, cbind(\"Recall\", recall, \"(Same as Sensitivity)\", \"\"))\n  vars <- rbind(vars, cbind(\"F1-Score\", f1, \"(Harmonic mean of\",\n                            \"precision and recall)\"))\n  vars <- rbind(vars, cbind(\"Odds ratios\", oddsratio, \"\", \"\"))\n  vars <- rbind(vars, cbind(\"False positive rate\", fpr, \"(type I error)\", \"\"))\n  vars <- rbind(vars, cbind(\"False negative rate\", fnr, \"(type II error)\", \"\"))\n  vars <- rbind(vars, cbind(\"Positive Likelihood ratio\", plr1, \"\", \"\"))\n  vars <- rbind(vars, cbind(\"Negative Likelihood ratio\", nlr1, \"\", \"\"))\n  return(vars)\n}\n\n############################################################################\n#####   Model Validity                                                  ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2016-12-01                                       ####\n############################################################################\n\nmodelValidity <- function (data, model, class, train=FALSE, calib.graph=FALSE)\n{\n  if (\"glm\" %in% class(model) | \"earth\" %in% class(model)) {\n    data$pred <- stats::predict(model, newdata = data, type = \"response\")\n  }\n  else {\n    data$pred <- stats::predict(model, newdata = data, type = \"prob\")[,2]\n  }\n  data <- subset(data, is.na(data[[\"pred\"]])==FALSE)\n  roc1 <- pROC::roc(data[, class], as.numeric(data[[\"pred\"]]))\n  ### GiViTI calibration test\n  if(train==FALSE) {\n    src=\"external\"\n  } else {\n    src=\"internal\"\n  }\n  if(is.factor(data[,class])==TRUE) {data[,class] <- as.numeric(data[,class])-1}\n  cb <- givitiR::givitiCalibrationBelt(o=data[,class],e=data[[\"pred\"]],devel=src)\n  if(calib.graph==TRUE) {\n    graphics::plot(cb, main = \"Model calibration\", xlab = \"Model predicted probability\", ylab = \"Observed outcome\")\n  }\n  cb <- round(cb$p.value,3)\n  ### Hoslem Lemeshow test\n  hl <- ResourceSelection::hoslem.test(model$y, stats::fitted(model), g = 10)$p.value\n  cm <- table(actual = data[, class], fitted = ifelse(data[[\"pred\"]] >= 0.5, 1, 0))\n  mmce <- 1 - (sum(diag(cm))/sum(cm))\n  #d <- sjstats::cod(model)$cod\n  vr <- MASS::stdres(model)\n  if (is.factor(data[, class])==TRUE) {data[,class] <- as.numeric(data[, class])-1}\n  acc <- ROSE::accuracy.meas(data[,class],data[[\"pred\"]])\n  srme <-sqrt((sum((data[, class] - data[[\"pred\"]])^2,na.rm=TRUE))/nrow(data))\n  vld <- cbind(auc = roc1$auc, cimin = pROC::ci(roc1)[1], cimax = pROC::ci(roc1)[3],\n               SRME = srme,\n               precision = acc$precision, recall = acc$recall, fscore = acc$F,\n               NPV =  InformationValue::npv(data[, class], data[[\"pred\"]]), mmce = mmce, Hosmer_Lemeshow = hl,GiViTI_calibration=cb)\n  vld <- round(vld, 3)\n  return(vld)\n}\n\n############################################################################\n#####   Model Cutoffs                                                   ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2017-07-09                                       ####\n############################################################################\ngetModelCutoffs <- function(pred, obs, div=10) {\n  #pred <- dc <- NULL\n  modValidity <- function(a,b,c,d,cutoff) {\n    ppv <- (a/(a+b))*100\n    npv <- (d/(c + d))*100\n    sensit <- (a/(c + a))*100\n    specif <- (d/(b + d))*100\n    prev <- ((a + c)/(a + b + c + d))*100\n    er <- ((b + c)/(a + b + c + d))*100\n    acc <- ((a + d)/(a + b + c + d))*100\n    prec <- (a/(a + b))*100\n    recall <- (a/(a + c))*100\n    lift <- ppv/prev\n    f1 <- ((2 * ((a/(a + b)) * (a/(a + c))))/((a/(a + b)) + (a/(a + c))))*100\n    return(cbind(cutoff=cutoff,TP=a,FP=b,FN=c,TN=d,sensitivity=sensit,specificity=specif,PPV=ppv,NPV=npv,accuracy=acc,error=er,prevalence=prev,lift=lift,precision=prec,recall=recall,F1_score=f1))\n  }\n  getQuintiles <- function(x,div=div) {\n    cut(x, breaks=c(stats::quantile(x, probs = seq(0, 1, by = 1/div),na.rm = TRUE)),\n        include.lowest=TRUE)\n  }\n  dc <- getQuintiles(pred,div=div)\n  fl <- unique(levels(dc))\n  res <- NULL\n  for (i in 1:length(fl)) {\n    # get the selected cutoff\n    idx <- dc %nin% fl[i]\n    pred1 <- rep(0,length(pred))\n    pred1[idx] <- 1\n    ####\n    mn <- min(pred[dc==fl[i]])\n    #tab1 <- table(obs,pred=ifelse(data[[\"pred\"]] > mn,1,0))\n    tab1 <- table(pred1,obs)\n    res <- rbind(res, round(modValidity(tab1[4],tab1[3],tab1[2],tab1[1],mn),3))\n  }\n  return(res)\n}\n\n############################################################################\n#####   AGE ADJUSTED RATES                                              ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2017-05-07                                       ####\n#####   Last Modified: 2020-11-03                                       ####\n############################################################################\n\n\nage_adjusted <- function(dataset,outcome,age,agemin=0,agemax=130,source=\"who\",alpha=0.05) {\n  weight <- n <- outcm1 <- wght <- pop <- adj <- res <- NULL\n  weighted_pct <- function(dataset,outcome,age,source,agemin,agemax) {\n    ###### generate tables\n    age_group <- c(\"0-4\",\"5-9\",\"10-14\",\"15-19\",\"20-24\",\"25-29\",\"30-34\",\n                   \"35-39\",\"40-44\",\"45-49\",\"50-54\",\"55-59\",\"60-64\",\n                   \"65-69\",\"70-74\",\"75-79\",\"80-84\",\"85-89\",\"90-94\",\n                   \"95-99\",\"100+\")\n    \n    age_min <- seq(0,100,5)\n    age_max <- c(seq(4,99,5),130)\n    who <- c(8860,8690,8600,8470,8220,7930,7610,7150,6590,6040,5370,\n             4550,3720,2960,2210,1520,910,440,150,40,5)\n    euro <- c(5000,5500,5500,5500,6000,6000,6500,7000,7000,7000,\n              7000,6500,6000,5500,5000,4000,2500,1500,800,180,20)\n    us <- c(20201362,20348657,20677194,22040343,21585999,21101849,\n            19962099,20179642,20890964,22708591,22298125,19664805,\n            16817924,12435263,9278166,7317795,5743327,3620459,\n            1448366,371244,53364)    \n    age.adjust <- data.frame(age_group, age_min, age_max, who, euro, us)\n    vn <- c('age_group', 'age_min', 'age_max', source)\n    weighting <- age.adjust[age.adjust$age_min>=agemin & age.adjust$age_max<=agemax,vn]\n    ages <- data.frame(age=seq(0,120,1))\n    \n    ages$age_min <- ifelse((ages$age/10)-floor(ages$age/10) < 0.5, floor(ages$age/10)*10, (floor(ages$age/10)*10)+5)\n    ages$age_max <- ifelse((ages$age/10)-floor(ages$age/10) < 0.5, (floor(ages$age/10)*10)+4, (floor(ages$age/10)*10)+9)\n    ages$age_min <- replace(ages$age_min, ages$age_min > 100,100)\n    ages$age_max <- replace(ages$age_max, ages$age_max > 100, 130)\n    \n    ##### take the correct weighting\n    tot <- sum(weighting[,source])\n    weighting$weight <- weighting[[source]]/tot\n    #weighting <- weighting[ages, on=c(\"age_min\",\"age_max\"), nomatch=0]\n    weighting <- merge(weighting, ages, by=c(\"age_min\",\"age_max\"))\n    dataset[,\"outcome\"] <- ifelse(dataset[,outcome]==1,1,0)\n    \n    ### correct for age names to be able to do the joint\n    dataset[,\"age\"] <- dataset[,age]\n    dataset <- data.frame(dataset)\n    unw <- (table(dataset[,\"outcome\"])/nrow(dataset))[2]\n    \n    #d1 <- dataset[weighting, on=\"age\", nomatch=0]\n    d1 <- merge(dataset, weighting, by=\"age\")\n    \n    #### we have yet calculated the weight.. use it!!!!\n    d1 <- d1[,c(\"age_group\",\"weight\",\"outcome\")]\n    d2 <-data.frame(outcm1 = (stats::aggregate(d1$outcome, by=list(d1$age_group),FUN=function(x) sum(x)))$x)\n    d2$wght <- (stats::aggregate(d1$weight, by=list(d1$age_group),FUN=function(x) max(x)))$x\n    d2$pop <- (stats::aggregate(d1$outcome, by=list(d1$age_group),FUN=function(x) length(x)))$x\n    d2$adj <- (d2$wght * d2$outcm1)/d2$pop\n    wgt <- sum(d2$adj)\n    return(cbind(unw,wgt))\n  }\n  t1 <- nrow(dataset)\n  evnt1 <- table(dataset[,outcome])[2]\n  res1 <- round(weighted_pct(dataset=dataset,outcome=outcome,age=age,source,agemin,agemax),5)\n  res1 <- round(res1,4)\n  unw1 <- round(Hmisc::binconf((t1*res1[1]),t1,alpha=alpha),4)\n  wgt1 <- round(Hmisc::binconf((t1*res1[2]),t1,alpha=alpha),4)\n  g1 <- list(Outcome=outcome,Population=t1,Events=evnt1,\n             crude=list(rate=res1[1]*100.0,\n                        CImin=unw1[2]*100.0,\n                        CImax=unw1[3]*100.0),\n             weighted=list(rate=res1[2]*100.0,\n                           CImin=wgt1[2]*100.0,\n                           CImax=wgt1[3]*100.0)\n  )\n  return(g1)\n}\n\n\n############################################################################\n#####   GET THE MISSINGNESS OF A DATASET                                ####\n#####   Author: Tomas Karpati M.D.                                      ####\n#####   Creation date: 2017-05-07                                       ####\n#####   Last Modified: 2020-11-03                                       ####\n############################################################################\n### search for the number & % of missinf\n### then count the number of rows with complete data\n\ngetMissingness <- function(data, getRows=FALSE) {\n  desc <- na_count <- na_cnt <- rn <- pred <- dc <- NULL\n  l <- nrow(data)\n  vn <- names(data)\n  ### copy the dataset and replace the NAs by 1 else 0\n  nadf <- data.frame(data)\n  cnt <- NULL\n  miss <- function(x) return(sum(is.na(x) ))\n  for(n in vn) {\n    nadf[[n]] <- ifelse(is.na(nadf[[n]])==TRUE,1,0)\n    cnt <- rbind(cnt, data.frame(n,sum(nadf[[n]])))\n  }\n  names(cnt) <- c(\"var\",\"na_count\")\n  cnt$rate <- round((cnt$na_count / nrow(nadf))*100,1)\n  ### now sum by column\n  nadf$na_cnt <- 0\n  nadf$na_cnt <- rowSums(nadf)\n  ### order descending the count of missings and leave only those with missings\n  cnt <- cnt[cnt$na_count>0,]\n  #cnt <- cnt[order(-rank(cnt$na_count))]\n  cnt <- cnt[order(-(cnt$na_count)),]\n  #totmiss <- nrow(nadf[nadf$na_cnt==0])\n  totmiss <- nrow(nadf[nadf$na_cnt==0,])\n  \n  idx <- NULL\n  msg <- (paste(\"This dataset has \", as.character(totmiss), \" (\",as.character(round(totmiss/nrow(data)*100,1)),\"%)\" ,\" complete rows. Original data has \",nrow(data),\" rows.\",sep=\"\"))\n  ### check id needs to return the row indexes\n  if(getRows==TRUE & totmiss != 0) {\n    nadf$rn <- base::seq_len(nrow(data))\n    idx <- nadf[nadf$na_cnt==0, \"rn\"]\n  }\n  message(msg)\n  #return(list(missingness=cnt, message=msg, rows=idx$rn))\n  return(list(missingness=cnt, message=msg, rows=idx))\n}","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-25T14:26:00.662513Z","iopub.execute_input":"2021-09-25T14:26:00.695142Z","iopub.status.idle":"2021-09-25T14:26:00.760297Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"library(dplyr)\nlibrary(devtools)\nlibrary(stats)\nlibrary(class)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(MESS)\nlibrary(rcompanion)\nlibrary(lsr)\nlibrary(dplyr)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(tidyverse)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(ggplot2)\nlibrary(lattice)\nlibrary(data.table)\n#### Installing and loading required libraries\nif(!require(fpc)) install.packages(\"fpc\")\nif(!require(dbscan)) install.packages(\"dbscan\")\nif(!require(devtools)) install.packages(\"devtools\")\n#devtools::install_github(\"kassambara/factoextra\")\nif(!require(factoextra)) install.packages(\"factoextra\")\nlibrary(mclust)\nif(!require(data.table)) install.packages(\"data.table\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:38:46.286371Z","iopub.execute_input":"2021-09-25T14:38:46.288092Z","iopub.status.idle":"2021-09-25T14:38:46.342514Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"Items1 <- read.csv(\"../input/items5/items_ff5.csv\")\nhead(Items1,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:26:05.857304Z","iopub.execute_input":"2021-09-25T14:26:05.858691Z","iopub.status.idle":"2021-09-25T14:26:33.938420Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"Items <- subset(Items1,select=-c(item_id,db_id,asin,title,description,num_of_sales_per_item,item_sell_rank_by_category))\n#Items1 <- subset(Items1,select=-c(item_id,db_id,asin,title,description,num_of_sales_per_item,item_sell_rank_by_category))\n\nlibrary(data.table)\nfor (n in names(Items)) {\n    if (n %like% \"num_of_sales\") {\n        Items[[n]][which(Items[[n]]>0)] <- 1\n        # rename col name to reflect exact meaning of data\n        names(Items)[names(Items)==n] <- str_sub(names(Items[n]),8,-1)\n    }\n}\n\nItems$location <- as.factor(Items$location)\nItems$condition <- as.factor(Items$condition)\nItems$success <- as.factor(Items$success)\nItems$season <- as.factor(Items$season)\nItems$sales_cyber_monday <- as.factor(Items$sales_cyber_monday)\nItems$sales_black_friday <- as.factor(Items$sales_black_friday)\nItems$sales_colombus_day <- as.factor(Items$sales_colombus_day)\nItems$sales_labor_day <- as.factor(Items$sales_labor_day)\nItems$sales_presidents_day <- as.factor(Items$sales_presidents_day)\nItems$sales_4th_july <- as.factor(Items$sales_4th_july)\nItems$sales_newyear <- as.factor(Items$sales_newyear)\nItems$sales_xms <- as.factor(Items$sales_xms)\nItems$reviews_cnt_category <- as.factor(Items$reviews_cnt_category)\nItems$brand_size <- as.factor(Items$brand_size)\nItems$popular_brand <- as.factor(Items$popular_brand)\nItems$creation_time <- as.Date(Items$creation_time,\"%d/%m/%Y\")\nItems$success <- ifelse(Items$success=='t',1,0)\n\n### characters\nstrlst <- NULL\nnumlst <- NULL\nfor (v in names(Items)) {\n        if (v != 'success') {\n            if(is.factor(Items[[v]])) {\n                strlst <- c(strlst,v)}\n            if(is.numeric(Items[[v]])) {numlst <- c(numlst, v)}\n            }\n}\nstrlst\n#numlst <- subset(numlst,TRUE,select=-c(creation_time,title,description))\nnumlst\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:26:33.940787Z","iopub.execute_input":"2021-09-25T14:26:33.942180Z","iopub.status.idle":"2021-09-25T14:26:38.518093Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dim(Items)\nsummary(Items)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:26:38.520302Z","iopub.execute_input":"2021-09-25T14:26:38.521620Z","iopub.status.idle":"2021-09-25T14:26:39.367389Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df1 <- data.frame(var1=character(),\n                  var2=character(),\n                  cramersV=numeric())\nstrlst1 <- c(strlst,'success')\ni <- 1 \nfor (m in strlst1) {\n    for (n in strlst1){\n        if (m != n){\n            suppressWarnings(cramersV <- cramersV(Items[[m]], Items[[n]]))\n            df1[i,] <- c(m,n,cramersV)\n            i <- i+1\n        }\n    }        \n}","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:26:39.369784Z","iopub.execute_input":"2021-09-25T14:26:39.371269Z","iopub.status.idle":"2021-09-25T14:27:06.255321Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tab1 <- suppressWarnings(Table1(data=subset(Items,select=-c(brand,creation_time))))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:06.257833Z","iopub.execute_input":"2021-09-25T14:27:06.259445Z","iopub.status.idle":"2021-09-25T14:27:11.462426Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tab1","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:11.464737Z","iopub.execute_input":"2021-09-25T14:27:11.466186Z","iopub.status.idle":"2021-09-25T14:27:11.543868Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Variable: sales_xms","metadata":{}},{"cell_type":"code","source":"summary(Items$sales_xms)\ntab1[tab1$Variables == 'sales_xms',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:11.547640Z","iopub.execute_input":"2021-09-25T14:27:11.549848Z","iopub.status.idle":"2021-09-25T14:27:11.602042Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#library(ggplot2)\noptions(repr.plot.width = 5, repr.plot.height = 5)\n    ggplot(data=Items) +\n        geom_bar(aes(sales_xms))+\n        labs(x=\"sales_xms\",title=\"sales_xms\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:11.605665Z","iopub.execute_input":"2021-09-25T14:27:11.607385Z","iopub.status.idle":"2021-09-25T14:27:12.332911Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"p <- wilcox.test(Items[[n]]~Items$sales_xms, alternative='two.sided')\np$p.value","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:12.335229Z","iopub.execute_input":"2021-09-25T14:27:12.336630Z","iopub.status.idle":"2021-09-25T14:27:13.940567Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        if (n %in% c('returns_cnt','star_rating')){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_xms, color=sales_xms)) +\n                    xlim(0,10)\n            }\n        else if (n %in% c('image_cnt','revised_star_rating')){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_xms, color=sales_xms)) +\n                    xlim(0,25)\n            }\n        else if (n == 'item_rating_rank_by_category'){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_xms, color=sales_xms))\n            }\n        else {\n           p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_xms, color=sales_xms)) +\n                    xlim(0,100) \n        }\n        i <- i+1\n}\nsuppressWarnings(grid.arrange(grobs=p, ncol=3))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:13.943039Z","iopub.execute_input":"2021-09-25T14:27:13.944542Z","iopub.status.idle":"2021-09-25T14:27:22.012848Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"library(ggplot2)\noptions(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=sales_xms, y=.data[[n]]),outlier.shape = NA)\n        i <- i+1\n}\ngrid.arrange(grobs=p, ncol=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:22.015354Z","iopub.execute_input":"2021-09-25T14:27:22.016796Z","iopub.status.idle":"2021-09-25T14:27:31.004715Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"we found weak association with profit percent","metadata":{}},{"cell_type":"markdown","source":"# Variable sales_cyber_monday","metadata":{}},{"cell_type":"code","source":"summary(Items$sales_cyber_monday)\ntab1[tab1$Variables == 'sales_cyber_monday',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:31.007474Z","iopub.execute_input":"2021-09-25T14:27:31.009040Z","iopub.status.idle":"2021-09-25T14:27:31.048021Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"library(ggplot2)\noptions(repr.plot.width = 5, repr.plot.height = 5)\n    ggplot(data=Items) +\n        geom_bar(aes(sales_cyber_monday))+\n        labs(x=\"sales_cyber_monday\",title=\"sales_cyber_monday\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:31.050462Z","iopub.execute_input":"2021-09-25T14:27:31.051863Z","iopub.status.idle":"2021-09-25T14:27:31.472850Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Check differences with other variables**","metadata":{}},{"cell_type":"code","source":"for (n in numlst){\n    print(c(\"Difference between\",n,\"and sales_cyber_monday\"))\n    p <- wilcox.test(Items[[n]]~Items$sales_cyber_monday, alternative='two.sided')\n    print(c(\"P-value = \",p$p.value))\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:31.475356Z","iopub.execute_input":"2021-09-25T14:27:31.476848Z","iopub.status.idle":"2021-09-25T14:27:55.485267Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Found difference with description_word_cnt, revised_star_rating, item_rating_rank_by_category","metadata":{}},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        if (n %in% c('returns_cnt','star_rating')){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_cyber_monday, color=sales_cyber_monday)) +\n                    xlim(0,10)\n            }\n        else if (n %in% c('image_cnt','revised_star_rating')){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_cyber_monday, color=sales_cyber_monday)) +\n                    xlim(0,25)\n            }\n        else if (n == 'item_rating_rank_by_category'){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_cyber_monday, color=sales_cyber_monday))\n            }\n        else {\n           p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=sales_cyber_monday, color=sales_cyber_monday)) +\n                    xlim(0,100) \n        }\n        i <- i+1\n}\nsuppressWarnings(grid.arrange(grobs=p, ncol=3))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:27:55.488219Z","iopub.execute_input":"2021-09-25T14:27:55.489784Z","iopub.status.idle":"2021-09-25T14:28:03.926150Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df1[(which(df1$var1 == 'sales_cyber_monday', arr.ind = TRUE)),] %>% arrange(desc(cramersV))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:03.928489Z","iopub.execute_input":"2021-09-25T14:28:03.929975Z","iopub.status.idle":"2021-09-25T14:28:03.969663Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"sale day- cyber monday is associated with image count,review count, star rating, rating rank by category and all other sale days.","metadata":{}},{"cell_type":"code","source":"library(ggplot2)\noptions(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=sales_cyber_monday, y=.data[[n]]),outlier.shape = NA)\n        i <- i+1\n}\ngrid.arrange(grobs=p, ncol=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:03.972074Z","iopub.execute_input":"2021-09-25T14:28:03.973495Z","iopub.status.idle":"2021-09-25T14:28:12.810025Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Variable: season","metadata":{}},{"cell_type":"code","source":"summary(Items$season)\ntab1[tab1$Variables == 'season',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:12.813714Z","iopub.execute_input":"2021-09-25T14:28:12.815888Z","iopub.status.idle":"2021-09-25T14:28:12.859642Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 5, repr.plot.height = 5)\n    ggplot(data=Items) +\n        geom_bar(aes(season))+\n        labs(x=\"season\",title=\"season\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:12.861969Z","iopub.execute_input":"2021-09-25T14:28:12.863350Z","iopub.status.idle":"2021-09-25T14:28:13.258262Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=season, y=.data[[n]]),outlier.shape = NA)\n        i <- i+1\n}\ngrid.arrange(grobs=p, ncol=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:13.260591Z","iopub.execute_input":"2021-09-25T14:28:13.262034Z","iopub.status.idle":"2021-09-25T14:28:23.048112Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        if (n %in% c('returns_cnt','star_rating')){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=season, color=season)) +\n                    xlim(0,10)\n            }\n        else if (n %in% c('image_cnt','revised_star_rating')){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=season, color=season)) +\n                    xlim(0,25)\n            }\n        else if (n == 'item_rating_rank_by_category'){\n            p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=season, color=season))\n            }\n        else {\n           p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]],\n                        group=season, color=season)) +\n                    xlim(0,100) \n        }\n        i <- i+1\n}\nsuppressWarnings(grid.arrange(grobs=p, ncol=3))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:23.050541Z","iopub.execute_input":"2021-09-25T14:28:23.052000Z","iopub.status.idle":"2021-09-25T14:28:32.195038Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"variable season show association with image count","metadata":{}},{"cell_type":"markdown","source":"# Variable: Location","metadata":{}},{"cell_type":"code","source":"summary(Items$location)\ntab1[tab1$Variables == 'location',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:32.198718Z","iopub.execute_input":"2021-09-25T14:28:32.200907Z","iopub.status.idle":"2021-09-25T14:28:32.243729Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 30)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=location, y=.data[[n]]))\n        p[[i+1]]<- ggplot(data=Items) + geom_boxplot(aes(x=location, y=.data[[n]]),outlier.shape = NA)+\n             ggtitle(\"No outliers\")\n        i <- i+2\n}\ngrid.arrange(grobs=p, ncol=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:28:32.246026Z","iopub.execute_input":"2021-09-25T14:28:32.247428Z","iopub.status.idle":"2021-09-25T14:29:04.531544Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]], group=location, color=location)) + xlim(0,100)\n        i <- i+1\n}\nsuppressWarnings(grid.arrange(grobs=p, ncol=3))\n\noptions(repr.plot.width = 5, repr.plot.height = 5)\nggplot(data=Items) +\n    geom_density(aes(x=Items$item_rating_rank_by_category, group=location, color=location))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:04.533983Z","iopub.execute_input":"2021-09-25T14:29:04.535449Z","iopub.status.idle":"2021-09-25T14:29:13.320016Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"location is associated with sale_labor_day, item rating rank by category and all prices (uk prices are expressed in $ with avg conversion rate)","metadata":{}},{"cell_type":"markdown","source":"# Variable: brand size","metadata":{}},{"cell_type":"code","source":"summary(Items$brand_size)\ntab1[tab1$Variables == 'brand_size',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:13.323892Z","iopub.execute_input":"2021-09-25T14:29:13.325650Z","iopub.status.idle":"2021-09-25T14:29:13.366348Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 8, repr.plot.height = 5)\n    ggplot(data=Items) +\n        geom_bar(aes(brand_size))+\n        labs(x=\"brand_size\",title=\"brand_size\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:13.368633Z","iopub.execute_input":"2021-09-25T14:29:13.370063Z","iopub.status.idle":"2021-09-25T14:29:13.759894Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"library(gridExtra)\nlibrary(grid)\noptions(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=brand_size, y=.data[[n]]),outlier.shape = NA)\n        i <- i+1\n}\ngrid.arrange(grobs=p, ncol=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:13.762226Z","iopub.execute_input":"2021-09-25T14:29:13.763607Z","iopub.status.idle":"2021-09-25T14:29:23.253884Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]], group=brand_size, color=brand_size))+xlim(0,100)\n        i <- i+1\n}\nsuppressWarnings(grid.arrange(grobs=p, ncol=3))\n\noptions(repr.plot.width = 5, repr.plot.height = 5)\nggplot(data=Items) +\n    geom_density(aes(x=Items$item_rating_rank_by_category, group=brand_size, color=brand_size))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:23.257870Z","iopub.execute_input":"2021-09-25T14:29:23.260286Z","iopub.status.idle":"2021-09-25T14:29:32.290680Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"brand size is associated with image count\n\nsmall brand size has avg of 0 for revised star rating","metadata":{}},{"cell_type":"markdown","source":"# Variable: reviews_cnt_category","metadata":{}},{"cell_type":"code","source":"table(Items$reviews_cnt_category)\ntab1[tab1$Variables == 'reviews_cnt_category',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:32.294743Z","iopub.execute_input":"2021-09-25T14:29:32.296881Z","iopub.status.idle":"2021-09-25T14:29:32.337186Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 8, repr.plot.height = 5)\npar(mar=c(1,1,1,1))\n    ggplot(data=Items) +\n        geom_bar(aes(reviews_cnt_category))+\n        labs(title=\"reviews_cnt_category\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:32.339632Z","iopub.execute_input":"2021-09-25T14:29:32.341093Z","iopub.status.idle":"2021-09-25T14:29:32.763171Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"library(gridExtra)\nlibrary(grid)\noptions(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=reviews_cnt_category, y=.data[[n]]),outlier.shape = NA)\n        i <- i+1\n}\ngrid.arrange(grobs=p, ncol=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:32.765724Z","iopub.execute_input":"2021-09-25T14:29:32.767213Z","iopub.status.idle":"2021-09-25T14:29:42.759481Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Variable reviews cnt category is correlated with item rating rank by category, revised star rating","metadata":{}},{"cell_type":"code","source":"options(repr.plot.width = 15, repr.plot.height = 5)\npar(mar=c(1,1,1,1),mfrow=c(1,2))\nfor (n in numlst) {\n                print(ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]], group=reviews_cnt_category, color=reviews_cnt_category))+xlim(0,25))\n}\n\npar(mar=c(1,1,1,1))\noptions(repr.plot.width = 5, repr.plot.height = 5)\nggplot(data=Items) +\n    geom_density(aes(x=Items$item_rating_rank_by_category, group=reviews_cnt_category, color=reviews_cnt_category))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:42.761842Z","iopub.execute_input":"2021-09-25T14:29:42.763247Z","iopub.status.idle":"2021-09-25T14:29:51.824631Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"We found association with item rating rank by category, revised star rating and all prices","metadata":{}},{"cell_type":"markdown","source":"# Variable: Popular brand","metadata":{}},{"cell_type":"code","source":"summary(Items$popular_brand)\ntab1[tab1$Variables == 'popular_brand',]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:51.827033Z","iopub.execute_input":"2021-09-25T14:29:51.828485Z","iopub.status.idle":"2021-09-25T14:29:51.868129Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"Items %>%\n  group_by(popular_brand) %>%\n  summarise(counts = n()) %>% mutate(prop = round(counts*100/sum(counts), 1))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:51.870505Z","iopub.execute_input":"2021-09-25T14:29:51.871936Z","iopub.status.idle":"2021-09-25T14:29:51.923145Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 8, repr.plot.height = 5)\npar(mar=c(1,1,1,1))\n    ggplot(data=Items) +\n        geom_bar(aes(popular_brand))+\n        labs(title=\"popular_brand\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:51.925578Z","iopub.execute_input":"2021-09-25T14:29:51.927088Z","iopub.status.idle":"2021-09-25T14:29:52.418261Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"library(gridExtra)\nlibrary(grid)\noptions(repr.plot.width = 20, repr.plot.height = 20)\np <- vector(mode = \"list\", length = length(numlst))\ni <- 1\nfor (n in numlst) {\n        p[[i]]<- ggplot(data=Items) + geom_boxplot(aes(x=popular_brand, y=.data[[n]]),outlier.shape = NA)\n        i <- i+1\n}\ngrid.arrange(grobs=p, ncol=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:29:52.421023Z","iopub.execute_input":"2021-09-25T14:29:52.422640Z","iopub.status.idle":"2021-09-25T14:30:02.448962Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 5)\npar(mar=c(3,3,3,3),mfrow=c(1,4))\nfor (n in numlst) {\n                print(ggplot(data=Items) +\n                    geom_density(aes(x=.data[[n]], group=popular_brand, color=popular_brand)) + xlim(0,50))\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:30:02.451588Z","iopub.execute_input":"2021-09-25T14:30:02.453126Z","iopub.status.idle":"2021-09-25T14:30:10.572228Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Popular brand is correlated to image count, revisd star rating, description word count, reviews count\n\nwe found association with profit percent, category size rank,all prices, ","metadata":{}},{"cell_type":"markdown","source":"# Variable : category","metadata":{}},{"cell_type":"code","source":"Items$category <- as.factor(Items$category)\n#table(Items1$category)\nstr(Items$category)\ntab1[tab1$Variables == 'category',] #%>% order(decreasing = TRUE)#order(method = desc)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:30:10.576231Z","iopub.execute_input":"2021-09-25T14:30:10.577919Z","iopub.status.idle":"2021-09-25T14:30:10.657947Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"head(Items,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:30:10.661501Z","iopub.execute_input":"2021-09-25T14:30:10.663170Z","iopub.status.idle":"2021-09-25T14:30:10.692119Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"high_cat <- Items %>% filter(Items$category %in% c('Home, Furniture & DIY','Health & Beauty','Home & Garden')) %>% summarize(n())\np <- high_cat/length(Items1$category) * 100\nprint(c('Percent of the three largest categories:',p))\n\ndf2 <- Items %>% group_by(category) %>% summarise(total=n())\ndf2\n\noptions(repr.plot.width = 20, repr.plot.height = 10)\nggplot(Items)+ geom_bar(aes(x=category))+\ntheme(axis.text.x = element_text(size = 9, angle = 45))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:39:39.454750Z","iopub.execute_input":"2021-09-25T14:39:39.456380Z","iopub.status.idle":"2021-09-25T14:39:40.309234Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"summary(df2)\ndf2 %>% filter(df2$total < 298)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:39:53.827091Z","iopub.execute_input":"2021-09-25T14:39:53.828697Z","iopub.status.idle":"2021-09-25T14:39:53.861336Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"The largest categories: 'Home, Furniture & DIY','Health & Beauty','Home & Garden' hold 43% of all the Items\nCategories : 'Antiques', 'Cars, Motorcycles & Vehicles', 'Sports Memorabilia' have less than 10 items.\n\nI will change this variable using label coding later","metadata":{}},{"cell_type":"markdown","source":"# Variable: brand","metadata":{}},{"cell_type":"code","source":"Items$brand <- as.factor(Items$brand)\nsummary(Items1$brand)\nstr(Items1$brand)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:40:01.796818Z","iopub.execute_input":"2021-09-25T14:40:01.798744Z","iopub.status.idle":"2021-09-25T14:40:02.809086Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"library(ggplot2)\noptions(repr.plot.width = 10, repr.plot.height = 20)\nmar=(adj=0.5)\ndf <- Items1 %>% \n    group_by(brand) %>% \n    summarise(total=n()) %>% arrange(desc(total))\nhead(df,10)\n#barplot(height=df$total, names=df$brand,horiz=T, las=1,cex.names=0.5)\nno_brand <- df %>% filter(df$total > 1000) %>% summarize(sum(total))\nno_brand/length(Items1$brand)\nsmall <- df %>% filter(df$total < 5) %>% summarize(sum(total))\nsmall/length(Items1$brand)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:40:02.812673Z","iopub.execute_input":"2021-09-25T14:40:02.814398Z","iopub.status.idle":"2021-09-25T14:40:05.616749Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"5% with no brand, 28% of all items are from a small brand (5 items or less)\n\nThis information is presented in top_brand variable.\nI'll drop this variable since it has too many levels","metadata":{}},{"cell_type":"code","source":"library(wordcloud)\noptions(repr.plot.width = 10, repr.plot.height = 10)\n\nkw <- Items %>% group_by(brand) %>% tally() %>% arrange(desc(n))\nsummary(kw$n)\nwordcloud(words = kw$brand, freq = kw$n, min.freq = 300,           \n             max.words=200, random.order=FALSE, rot.per=0.35,            \n             colors=brewer.pal(8, \"Dark2\"))\n\nwordcloud(words = kw$brand[kw$brand != c(\"Not Applicable\",\"None\")], freq = kw$n, min.freq = 300,           \n             max.words=200, random.order=FALSE, rot.per=0.35,            \n             colors=brewer.pal(8, \"Dark2\"))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T14:43:56.235630Z","iopub.execute_input":"2021-09-25T14:43:56.237277Z","iopub.status.idle":"2021-09-25T14:43:58.723808Z"},"trusted":true},"execution_count":69,"outputs":[]}]}