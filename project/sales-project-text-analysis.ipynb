{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T13:38:29.958539Z","iopub.execute_input":"2021-09-27T13:38:29.959474Z","iopub.status.idle":"2021-09-27T13:38:30.023590Z","shell.execute_reply.started":"2021-09-27T13:38:29.959380Z","shell.execute_reply":"2021-09-27T13:38:30.022624Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"Items = pd.read_csv(\"../input/items-ff-final5a/Items_ff_final5.csv\")\nItems.head()\n#Items.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:30.025223Z","iopub.execute_input":"2021-09-27T13:38:30.025440Z","iopub.status.idle":"2021-09-27T13:38:39.028543Z","shell.execute_reply.started":"2021-09-27T13:38:30.025416Z","shell.execute_reply":"2021-09-27T13:38:39.027599Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Items.rename(columns={'Items1$total_sales': 'total_sales'}, inplace=True)\n#Items.drop(columns=['description'], inplace=True)\nItems['location'] = Items['location'].astype('category')\nItems['condition'] = Items['condition'].astype('category')\nItems['star_rating'] = Items['star_rating'].astype('category')\nItems['revised_star_rating'] = Items['revised_star_rating'].astype('category')\nItems['sales_cyber_monday'] = Items['sales_cyber_monday'].astype('category')\nItems['sales_black_friday'] = Items['sales_black_friday'].astype('category')\nItems['sales_colombus_day'] = Items['sales_colombus_day'].astype('category')\nItems['sales_labor_day'] = Items['sales_labor_day'].astype('category')\nItems['sales_presidents_day'] = Items['sales_presidents_day'].astype('category')\nItems['sales_4th_july'] = Items['sales_4th_july'].astype('category')\nItems['sales_newyear'] = Items['sales_newyear'].astype('category')\nItems['sales_xms'] = Items['sales_xms'].astype('category')\nItems['success'] = Items['success'].astype('category')\nItems['brand_size'] = Items['brand_size'].astype('category')\nItems['popular_brand'] = Items['popular_brand'].astype('category')\nItems['category_size_rank_q'] = Items['category_size_rank_q'].astype('category')\nItems['review_count_log'] = Items['review_count_log'].astype('category')\nItems['price_diff_competitor_log'] = Items['price_diff_competitor_log'].astype('category')\nItems['profit_pct_sqrt'] = Items['profit_pct_sqrt'].astype('category')\nItems['reviews_cnt_category'] = Items['reviews_cnt_category'].astype('category')\nItems['creation_time'] = Items['creation_time'].astype('datetime64')\nItems.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:39.029780Z","iopub.execute_input":"2021-09-27T13:38:39.030050Z","iopub.status.idle":"2021-09-27T13:38:39.617772Z","shell.execute_reply.started":"2021-09-27T13:38:39.030020Z","shell.execute_reply":"2021-09-27T13:38:39.616819Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#!pip install nltk\nimport nltk\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:39.619192Z","iopub.execute_input":"2021-09-27T13:38:39.619444Z","iopub.status.idle":"2021-09-27T13:38:41.510157Z","shell.execute_reply.started":"2021-09-27T13:38:39.619417Z","shell.execute_reply":"2021-09-27T13:38:41.509311Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:41.512244Z","iopub.execute_input":"2021-09-27T13:38:41.512467Z","iopub.status.idle":"2021-09-27T13:38:41.517240Z","shell.execute_reply.started":"2021-09-27T13:38:41.512441Z","shell.execute_reply":"2021-09-27T13:38:41.516154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text = Items['description'].astype('str')\n#text = text.sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:41.519237Z","iopub.execute_input":"2021-09-27T13:38:41.519561Z","iopub.status.idle":"2021-09-27T13:38:41.565532Z","shell.execute_reply.started":"2021-09-27T13:38:41.519519Z","shell.execute_reply":"2021-09-27T13:38:41.564638Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"text_df = pd.DataFrame()\ntext_df['description'] = text\ntext_df.head\ntext_df['char_count'] = text_df['description'].str.len() ## this also includes spaces\ntext_df[['description','char_count']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:41.566762Z","iopub.execute_input":"2021-09-27T13:38:41.567052Z","iopub.status.idle":"2021-09-27T13:38:42.088017Z","shell.execute_reply.started":"2021-09-27T13:38:41.567019Z","shell.execute_reply":"2021-09-27T13:38:42.087229Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Average word length\ndef avg_word(sentence):\n  words = sentence.split()\n  return (sum(len(word) for word in words)/len(words))\n\ntext_df['avg_word'] = text_df['description'].apply(lambda x: avg_word(x))\ntext_df[['description','avg_word']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:42.089200Z","iopub.execute_input":"2021-09-27T13:38:42.089442Z","iopub.status.idle":"2021-09-27T13:38:46.222857Z","shell.execute_reply.started":"2021-09-27T13:38:42.089414Z","shell.execute_reply":"2021-09-27T13:38:46.222034Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Number of stop words\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n\ntext_df['stopwords'] = text_df['description'].apply(lambda x: len([x for x in x.split() if x in stop]))\ntext_df[['description','stopwords']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:38:46.224175Z","iopub.execute_input":"2021-09-27T13:38:46.224436Z","iopub.status.idle":"2021-09-27T13:39:44.473897Z","shell.execute_reply.started":"2021-09-27T13:38:46.224398Z","shell.execute_reply":"2021-09-27T13:39:44.472986Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Number of numeric characters\ntext_df['numerics'] = text_df['description'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\ntext_df[['description','numerics']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:39:44.475012Z","iopub.execute_input":"2021-09-27T13:39:44.475214Z","iopub.status.idle":"2021-09-27T13:39:48.017471Z","shell.execute_reply.started":"2021-09-27T13:39:44.475190Z","shell.execute_reply":"2021-09-27T13:39:48.016698Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Number of UPPER CASE words\ntext_df['upper'] = text_df['description'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\ntext_df[['description','upper']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:39:48.018588Z","iopub.execute_input":"2021-09-27T13:39:48.018819Z","iopub.status.idle":"2021-09-27T13:39:51.685001Z","shell.execute_reply.started":"2021-09-27T13:39:48.018784Z","shell.execute_reply":"2021-09-27T13:39:51.684332Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing**","metadata":{}},{"cell_type":"code","source":"# Lower case,remove stop words and Punctuation\nfrom nltk.corpus import stopwords\n\ntext_df['text_df'] = text_df['description'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ntext_df['text_df'] = text_df['text_df'].str.replace('[^\\w\\s]','')\n\nstop = stopwords.words('english')\ntext_df['text_df'] = text_df['text_df'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\ntext_df['description'].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:39:51.686077Z","iopub.execute_input":"2021-09-27T13:39:51.686523Z","iopub.status.idle":"2021-09-27T13:41:09.104982Z","shell.execute_reply.started":"2021-09-27T13:39:51.686475Z","shell.execute_reply":"2021-09-27T13:41:09.103972Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"freq = pd.Series(' '.join(text_df['description']).split()).value_counts()[:10]\nfreq\nfreq = list(freq.index)\ntext_df['description'] = text_df['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\ntext_df['description'].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:41:09.106881Z","iopub.execute_input":"2021-09-27T13:41:09.107221Z","iopub.status.idle":"2021-09-27T13:41:31.997870Z","shell.execute_reply.started":"2021-09-27T13:41:09.107179Z","shell.execute_reply":"2021-09-27T13:41:31.996988Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"freq_rare = pd.Series(' '.join(text_df['description']).split()).value_counts()[-10:]\nfreq_rare\nfreq = list(freq_rare.index)\ntext_df['description'] = text_df['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_rare))\ntext_df['description'].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:41:32.002241Z","iopub.execute_input":"2021-09-27T13:41:32.002519Z","iopub.status.idle":"2021-09-27T13:42:19.381819Z","shell.execute_reply.started":"2021-09-27T13:41:32.002491Z","shell.execute_reply":"2021-09-27T13:42:19.380949Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from textblob import TextBlob\ntext_df['description'][:5].apply(lambda x: str(TextBlob(x).correct()))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:42:19.383121Z","iopub.execute_input":"2021-09-27T13:42:19.383379Z","iopub.status.idle":"2021-09-27T13:42:25.978717Z","shell.execute_reply.started":"2021-09-27T13:42:19.383348Z","shell.execute_reply":"2021-09-27T13:42:25.978054Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Tokenization**","metadata":{}},{"cell_type":"code","source":"from textblob import TextBlob\nTextBlob(text_df['description'][1]).words","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:42:25.979790Z","iopub.execute_input":"2021-09-27T13:42:25.980599Z","iopub.status.idle":"2021-09-27T13:42:26.000196Z","shell.execute_reply.started":"2021-09-27T13:42:25.980563Z","shell.execute_reply":"2021-09-27T13:42:25.999241Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from textblob import Word\ntext_df['description'] = text_df['description'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\ntext_df['description'].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:42:26.001566Z","iopub.execute_input":"2021-09-27T13:42:26.002226Z","iopub.status.idle":"2021-09-27T13:45:06.940866Z","shell.execute_reply.started":"2021-09-27T13:42:26.002185Z","shell.execute_reply":"2021-09-27T13:45:06.940041Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**Sentiment Analysis**","metadata":{}},{"cell_type":"code","source":"text_df['sentiment'] = text_df['description'].apply(lambda x: TextBlob(x).sentiment[0] )\ntext_df[['description','sentiment']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:45:06.941986Z","iopub.execute_input":"2021-09-27T13:45:06.942213Z","iopub.status.idle":"2021-09-27T13:50:35.107067Z","shell.execute_reply.started":"2021-09-27T13:45:06.942187Z","shell.execute_reply":"2021-09-27T13:50:35.106260Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"text_df.drop('description',axis=1, inplace = True)\ntext_df.to_csv(\"./text_analysis_2\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T13:50:35.108116Z","iopub.execute_input":"2021-09-27T13:50:35.109003Z","iopub.status.idle":"2021-09-27T13:50:44.412248Z","shell.execute_reply.started":"2021-09-27T13:50:35.108951Z","shell.execute_reply":"2021-09-27T13:50:44.411263Z"},"trusted":true},"execution_count":19,"outputs":[]}]}